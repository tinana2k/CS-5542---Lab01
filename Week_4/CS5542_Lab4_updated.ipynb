{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tinana2k/Comp-Sci-5542-Tina-Nguyen/blob/main/Week_4/CS5542_Lab4_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df3e229a",
      "metadata": {
        "id": "df3e229a"
      },
      "source": [
        "# CS 5542 ‚Äî Lab 4 Notebook (Team Project)\n",
        "## RAG Application Integration, Deployment, and Monitoring (Deadline: Feb. 12, 2026)\n",
        "\n",
        "**Purpose:** This notebook is a **project-aligned template** for Lab 4. Your team should reuse your Lab-3 multimodal RAG pipeline and integrate it into a **deployable application** with **automatic logging** and **failure analysis**.\n",
        "\n",
        "### Submission policy\n",
        "- **Survey:** submitted **individually**\n",
        "- **Deliverables (GitHub repo / notebook / report / deployment link):** submitted **as a team**\n",
        "\n",
        "### Team-size requirement\n",
        "- **1‚Äì2 students:** Base requirements + **1 extension**\n",
        "- **3‚Äì4 students:** Base requirements + **2‚Äì3 extensions**\n",
        "\n",
        "---\n",
        "\n",
        "## What you will build (at minimum)\n",
        "1. A **Streamlit app** that accepts a question and returns:\n",
        "   - an **answer**\n",
        "   - **retrieved evidence** with citations\n",
        "   - **metrics panel** (latency, P@5, R@10 if applicable)\n",
        "2. An **automatic logger** that appends to: `logs/query_metrics.csv`\n",
        "3. A **mini gold set** of **5 project queries** (Q1‚ÄìQ5) for evaluation\n",
        "4. **Two failure cases** with root cause + proposed fix\n",
        "\n",
        "> **Important:** Lab 4 focuses on **application integration and deployment**, not on redesigning retrieval. Prefer reusing your Lab-3 modules.\n",
        "\n",
        "---\n",
        "\n",
        "## Recommended repository structure (for your team repo)\n",
        "```\n",
        "/app/              # Streamlit UI (required)\n",
        "/rag/              # Retrieval + indexing modules (reuse from Lab 3)\n",
        "/logs/             # query_metrics.csv (auto-created)\n",
        "/data/             # your project-aligned PDFs/images (do NOT commit large/private data)\n",
        "/api/              # optional FastAPI backend (extension)\n",
        "/notebooks/        # this notebook\n",
        "requirements.txt\n",
        "README.md\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Contents of this notebook\n",
        "1. Setup & environment checks  \n",
        "2. Project dataset wiring (connect your Lab-3 ingestion)  \n",
        "3. Mini gold set (Q1‚ÄìQ5)  \n",
        "4. Retrieval + answer function (reuse your Lab-3 pipeline)  \n",
        "5. Evaluation + logging (required)  \n",
        "6. Streamlit app skeleton (required)  \n",
        "7. Optional extension: FastAPI backend  \n",
        "8. Deployment checklist + failure analysis template\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xYMU614tBEP3",
        "outputId": "7c9e30a0-8725-45a2-e2aa-05d0a544f866"
      },
      "id": "xYMU614tBEP3",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-34cf9bd0-d6d1-46b6-aeb0-0e137c33a9b7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-34cf9bd0-d6d1-46b6-aeb0-0e137c33a9b7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving data.zip to data (2).zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil, os, zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "zip_path = \"data.zip\"\n",
        "\n",
        "# Remove old extracted folder if it exists (prevents stale files)\n",
        "if Path(\"data\").exists():\n",
        "    shutil.rmtree(\"data\")\n",
        "\n",
        "# Extract fresh\n",
        "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
        "    z.extractall(\".\")\n",
        "\n",
        "print(\"‚úÖ Extracted fresh\")\n",
        "print(\"Docs now:\", sorted(os.listdir(\"data/docs\")) if Path(\"data/docs\").exists() else \"NO data/docs folder\")\n",
        "print(\"Images now:\", sorted(os.listdir(\"data/images\")) if Path(\"data/images\").exists() else \"NO data/images folder\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX_ts48FGJs3",
        "outputId": "e239767d-857c-48fc-c460-f34105ce118c"
      },
      "id": "nX_ts48FGJs3",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted fresh\n",
            "Docs now: ['doc1.pdf', 'doc2.pdf', 'doc3.pdf', 'doc4.pdf', 'doc5.pdf']\n",
            "Images now: ['cyber_kill_chain.png', 'impact_likelihood_matrix.png', 'network_system_security.png', 'nist_framework.png', 'risk_management.png', 'risk_management_process.png', 'security_audit_process.png', 'soc2_requirements.png', 'website_security_audit.png', 'zero_trust.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "Jdz6kAJaThoY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdz6kAJaThoY",
        "outputId": "069d6cdd-6efb-41ba-8e76-1b25e8fdcc89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ÑπÔ∏è Skipping numeric demo file creation (not in dataset)\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "docs_dir = Path(\"data/docs\")\n",
        "docs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Only create numeric demo if explicitly needed\n",
        "create_demo_numeric = False   # üî¥ Change to True only if required by lab rubric\n",
        "\n",
        "if create_demo_numeric:\n",
        "    numeric_path = docs_dir / \"numeric_demo.txt\"\n",
        "    numeric_path.write_text(\n",
        "        \"Fusion Hyperparameters (Table 1)\\n\"\n",
        "        \"alpha = 0.50\\n\"\n",
        "        \"top_k = 5\\n\"\n",
        "        \"missing_evidence_score_threshold = 0.05\\n\"\n",
        "        \"latency_alert_ms = 2000\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    print(\"‚úÖ Created numeric demo file\")\n",
        "else:\n",
        "    print(\"‚ÑπÔ∏è Skipping numeric demo file creation (not in dataset)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "8AOvgEV9Q-8g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8AOvgEV9Q-8g",
        "outputId": "7ba74762-6a5a-4f05-ccbb-e09e0a684ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found PDF docs: 5\n",
            "First document: doc1.pdf\n"
          ]
        }
      ],
      "source": [
        "# Sanity check: ensure PDF docs are loaded\n",
        "import os, glob\n",
        "\n",
        "doc_files = glob.glob('./data/docs/*.pdf')\n",
        "print(\"Found PDF docs:\", len(doc_files))\n",
        "\n",
        "assert len(doc_files) > 0, \"No PDF docs found. Ensure the ZIP was extracted correctly.\"\n",
        "\n",
        "# Preview first PDF filename (we can't directly print PDF text yet)\n",
        "print(\"First document:\", os.path.basename(doc_files[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install PyPDF2\n"
      ],
      "metadata": {
        "id": "ehVY1_TmIjsp"
      },
      "id": "ehVY1_TmIjsp",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pycryptodome"
      ],
      "metadata": {
        "id": "79SF43rYJtg9"
      },
      "id": "79SF43rYJtg9",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install pycryptodome cryptography\n"
      ],
      "metadata": {
        "id": "7KKGF8yWKa2c"
      },
      "id": "7KKGF8yWKa2c",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import Crypto\n",
        "print(\"Crypto OK:\", Crypto.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BwsmnpnKiXM",
        "outputId": "be69e467-b0f5-408c-ce08-a99ba79a3746"
      },
      "id": "-BwsmnpnKiXM",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crypto OK: 3.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "xGbb-SjVSN21",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGbb-SjVSN21",
        "outputId": "03d62fa9-83e0-4387-d80c-4480d7d17643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded documents: 5\n",
            "‚ö†Ô∏è Skipped: 0\n",
            "\n",
            "Example doc_id: doc1.pdf\n",
            "State Data Breach Notification Laws\n",
            "Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team\n",
            "FOR INFORMATIONAL PURPOSES ONLY \n",
            "4824-6127-3219.41 1 ‚ñ†Exceptions based on compliance with other laws, such as \n",
            "the Health Insurance Portability and Accountability Act \n",
            "(HIPAA) or Gramm-Leach-Bliley Act (GLBA).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import glob, os, sys, subprocess\n",
        "\n",
        "# Ensure dependencies\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "try:\n",
        "    from PyPDF2 import PdfReader\n",
        "except ModuleNotFoundError:\n",
        "    pip_install(\"PyPDF2\")\n",
        "    from PyPDF2 import PdfReader\n",
        "\n",
        "# Needed for AES-encrypted PDFs\n",
        "try:\n",
        "    import Crypto  # noqa: F401\n",
        "except ModuleNotFoundError:\n",
        "    pip_install(\"pycryptodome\")\n",
        "\n",
        "DOC_DIR = \"./data/docs\"\n",
        "doc_files = sorted(glob.glob(os.path.join(DOC_DIR, \"*.pdf\")))\n",
        "\n",
        "if not doc_files:\n",
        "    raise RuntimeError(\"No .pdf documents found in ./data/docs. Ensure the ZIP was extracted.\")\n",
        "\n",
        "documents = []\n",
        "skipped = []\n",
        "\n",
        "for p in doc_files:\n",
        "    try:\n",
        "        reader = PdfReader(p)\n",
        "\n",
        "        # If encrypted, try empty password\n",
        "        if getattr(reader, \"is_encrypted\", False):\n",
        "            try:\n",
        "                reader.decrypt(\"\")  # common case: encrypted but no password\n",
        "            except Exception as e:\n",
        "                skipped.append((os.path.basename(p), f\"Encrypted (decrypt failed): {e}\"))\n",
        "                continue\n",
        "\n",
        "        text_parts = []\n",
        "        for page in reader.pages:\n",
        "            extracted = page.extract_text()\n",
        "            if extracted:\n",
        "                text_parts.append(extracted)\n",
        "\n",
        "        txt = \"\\n\".join(text_parts).strip()\n",
        "        if not txt:\n",
        "            skipped.append((os.path.basename(p), \"No extractable text\"))\n",
        "            continue\n",
        "\n",
        "        documents.append({\"doc_id\": os.path.basename(p), \"source\": p, \"text\": txt})\n",
        "\n",
        "    except Exception as e:\n",
        "        skipped.append((os.path.basename(p), str(e)))\n",
        "\n",
        "print(\"‚úÖ Loaded documents:\", len(documents))\n",
        "print(\"‚ö†Ô∏è Skipped:\", len(skipped))\n",
        "for name, reason in skipped[:10]:\n",
        "    print(\" -\", name, \"->\", reason)\n",
        "\n",
        "if documents:\n",
        "    print(\"\\nExample doc_id:\", documents[0][\"doc_id\"])\n",
        "    print(documents[0][\"text\"][:300])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob, os\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "DOC_DIR = \"./data/docs\"\n",
        "doc_files = sorted(glob.glob(os.path.join(DOC_DIR, \"*.pdf\")))\n",
        "\n",
        "# If decrypted version exists, prefer it over the original\n",
        "if os.path.exists(os.path.join(DOC_DIR, \"doc5_decrypted.pdf\")):\n",
        "    doc_files = [p for p in doc_files if not p.endswith(\"doc5.pdf\")]\n",
        "\n",
        "documents = []\n",
        "skipped = []\n",
        "\n",
        "for p in doc_files:\n",
        "    try:\n",
        "        reader = PdfReader(p)\n",
        "        text_parts = []\n",
        "        for page in reader.pages:\n",
        "            t = page.extract_text()\n",
        "            if t:\n",
        "                text_parts.append(t)\n",
        "        txt = \"\\n\".join(text_parts).strip()\n",
        "        if not txt:\n",
        "            skipped.append((os.path.basename(p), \"No extractable text\"))\n",
        "            continue\n",
        "        documents.append({\"doc_id\": os.path.basename(p), \"source\": p, \"text\": txt})\n",
        "    except Exception as e:\n",
        "        skipped.append((os.path.basename(p), str(e)))\n",
        "\n",
        "print(\"‚úÖ Loaded documents:\", len(documents))\n",
        "print(\"‚ö†Ô∏è Skipped:\", skipped)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TY487-ZcLcai",
        "outputId": "2be54080-3667-45e9-8dcf-bf56c2d05bba"
      },
      "id": "TY487-ZcLcai",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded documents: 5\n",
            "‚ö†Ô∏è Skipped: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "vLkoKvfRbK41",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLkoKvfRbK41",
        "outputId": "590579c8-0500-4c26-8aeb-f6ecdc875422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded images: 10\n",
            "Example image: cyber_kill_chain.png\n",
            "Caption: cyber kill chain\n",
            "‚úÖ Unified evidence items: 15 (text: 5 , images: 10 )\n"
          ]
        }
      ],
      "source": [
        "# Load demo images and create lightweight text surrogates (captions) for multimodal retrieval\n",
        "import glob, os\n",
        "\n",
        "IMG_DIR = './data/images'\n",
        "img_files = sorted(glob.glob(os.path.join(IMG_DIR, '*.*')))\n",
        "img_files = [p for p in img_files if p.lower().endswith(('.png','.jpg','.jpeg','.webp'))]\n",
        "\n",
        "# Minimal captions so images participate in retrieval without requiring a vision encoder\n",
        "IMAGE_CAPTIONS = {\n",
        "    'rag_pipeline.png': 'RAG pipeline diagram: ingest, chunk, index, retrieve top-k evidence, build context, generate grounded answer, log metrics for monitoring.',\n",
        "    'retrieval_modes.png': 'Retrieval modes diagram: BM25 keyword, vector semantic, hybrid fusion, multi-hop hop-1 to hop-2 refinement.',\n",
        "}\n",
        "\n",
        "images = []\n",
        "for p in img_files:\n",
        "    fid = os.path.basename(p)\n",
        "    cap = IMAGE_CAPTIONS.get(fid, fid.replace('_',' ').replace('.png','').replace('.jpg',''))\n",
        "    images.append({'img_id': fid, 'source': p, 'text': cap})\n",
        "\n",
        "print('‚úÖ Loaded images:', len(images))\n",
        "if images:\n",
        "    print('Example image:', images[0]['img_id'])\n",
        "    print('Caption:', images[0]['text'])\n",
        "\n",
        "# Unified evidence store used by retrieval (text + images)\n",
        "items = []\n",
        "for d in documents:\n",
        "    items.append({\n",
        "        'evidence_id': d.get('doc_id') or os.path.basename(d.get('source','')),\n",
        "        'modality': 'text',\n",
        "        'source': d.get('source'),\n",
        "        'text': d.get('text','')\n",
        "    })\n",
        "for im in images:\n",
        "    items.append({\n",
        "        'evidence_id': f\"img::{im['img_id']}\",\n",
        "        'modality': 'image',\n",
        "        'source': im.get('source'),\n",
        "        'text': im.get('text','')\n",
        "    })\n",
        "\n",
        "assert len(items) > 0, 'Evidence store is empty.'\n",
        "print('‚úÖ Unified evidence items:', len(items), '(text:', len(documents), ', images:', len(images), ')')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47e549d1",
      "metadata": {
        "id": "47e549d1"
      },
      "source": [
        "# 1) Setup & environment checks\n",
        "\n",
        "This notebook includes **safe defaults** and **lightweight code examples**.  \n",
        "Replace the placeholder pieces with your Lab-3 implementation (PDF parsing, OCR, multimodal evidence, hybrid retrieval, reranking).\n",
        "\n",
        "### Install dependencies (edit as needed)\n",
        "- Core: `streamlit`, `pandas`, `numpy`, `requests`\n",
        "- Optional: `fastapi`, `uvicorn` (if you do the FastAPI extension)\n",
        "- Retrieval examples: `scikit-learn` (TF-IDF baseline), optionally `sentence-transformers` (dense embeddings)\n",
        "\n",
        "> In your team repo, always keep a clean `requirements.txt` for reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "425991a8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "425991a8",
        "outputId": "a74a5926-3d2f-47af-bd4d-53fc9bd090a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python OK. Working directory: /content\n"
          ]
        }
      ],
      "source": [
        "# If running in Colab or fresh environment, uncomment installs:\n",
        "# !pip -q install streamlit pandas numpy requests scikit-learn\n",
        "# # Optional (FastAPI extension):\n",
        "# !pip -q install fastapi uvicorn pydantic\n",
        "# # Optional (dense retrieval):\n",
        "# !pip -q install sentence-transformers\n",
        "\n",
        "import os, json, time\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "print(\"Python OK. Working directory:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c805bf7",
      "metadata": {
        "id": "5c805bf7"
      },
      "source": [
        "# 2) Project paths + configuration\n",
        "\n",
        "Set your project data paths and key parameters here.\n",
        "\n",
        "- Do **not** hardcode secrets (API keys) in notebooks or repos.\n",
        "- If you use a hosted LLM, read from environment variables locally.\n",
        "\n",
        "**Tip:** Keep these settings mirrored in `rag/config.py` so your Streamlit app uses the same config.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "1d483405",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d483405",
        "outputId": "8fbbae8c-9aa3-4c8b-e5cf-9bb9cdc6a11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lab4Config(project_name='YOUR_PROJECT_NAME', data_dir='./data', logs_dir='./logs', log_file='./logs/query_metrics.csv', top_k_default=10, eval_p_at=5, eval_r_at=10)\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Lab4Config:\n",
        "    project_name: str = \"YOUR_PROJECT_NAME\"\n",
        "    data_dir: str = \"./data\"        # where your PDFs/images live locally\n",
        "    logs_dir: str = \"./logs\"\n",
        "    log_file: str = \"./logs/query_metrics.csv\"\n",
        "    top_k_default: int = 10\n",
        "    eval_p_at: int = 5\n",
        "    eval_r_at: int = 10\n",
        "\n",
        "cfg = Lab4Config()\n",
        "Path(cfg.logs_dir).mkdir(parents=True, exist_ok=True)\n",
        "print(cfg)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c5030e",
      "metadata": {
        "id": "d5c5030e"
      },
      "source": [
        "# 3) Dataset wiring (project-aligned)\n",
        "\n",
        "For Lab 4, your **data, application UI, and models** must be aligned to your team project.\n",
        "\n",
        "## Required (project-aligned)\n",
        "- 2‚Äì6 PDFs\n",
        "- 5‚Äì15 images/figures/tables (if your project is multimodal)\n",
        "\n",
        "## In Lab 3 you likely had:\n",
        "- PDF text extraction (PyMuPDF)\n",
        "- OCR / captions for figures or scanned pages\n",
        "- Chunking + indexing (dense/sparse/hybrid)\n",
        "- Reranking (optional)\n",
        "- Grounded answer generation with citations\n",
        "\n",
        "### What to do here\n",
        "1. Point this notebook to your dataset folder.\n",
        "2. Load *already-prepared* chunks/evidence from Lab 3 (recommended), OR\n",
        "3. Call your Lab-3 ingestion function to rebuild the index.\n",
        "\n",
        "Below is a **minimal example** that loads plain text files as ‚Äúdocuments‚Äù so the notebook is runnable even without PDFs.\n",
        "Replace it with your Lab-3 ingestion code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "20f0f725",
      "metadata": {
        "id": "20f0f725",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54abaf8f-d815-42d2-8905-714419136ae2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loaded docs: 5\n",
            "‚ö†Ô∏è Skipped: 0\n",
            "\n",
            "Keys: dict_keys(['doc_id', 'source', 'text'])\n",
            "Example doc_id: doc1\n",
            "State Data Breach Notification Laws\n",
            "Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team\n",
            "FOR INFORMATIONAL PURPOSES ONLY \n",
            "4824-6127-3219.41 1 ‚ñ†Exceptions based on compliance with other laws, such as \n",
            "the Health Insurance Portability and Accountability Act \n",
            "(HIPAA) or Gramm-Leach-Bliley Act (GLBA).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Minimal runnable loader for YOUR dataset (PDFs in ./data/docs)\n",
        "from pathlib import Path\n",
        "import sys, subprocess\n",
        "\n",
        "docs_dir = Path(\"data\") / \"docs\"\n",
        "docs_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# --- install deps if missing ---\n",
        "def pip_install(pkg: str):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "try:\n",
        "    from PyPDF2 import PdfReader\n",
        "except ModuleNotFoundError:\n",
        "    pip_install(\"PyPDF2\")\n",
        "    from PyPDF2 import PdfReader\n",
        "\n",
        "# Optional: try to decrypt AES PDFs more reliably\n",
        "# (If it still doesn't work, we'll skip encrypted PDFs)\n",
        "try:\n",
        "    import Crypto  # noqa: F401\n",
        "except ModuleNotFoundError:\n",
        "    try:\n",
        "        pip_install(\"pycryptodome\")\n",
        "    except Exception:\n",
        "        pass  # okay if install fails; we'll still load non-encrypted PDFs\n",
        "\n",
        "def load_pdf_docs(docs_path: Path):\n",
        "    items = []\n",
        "    skipped = []\n",
        "\n",
        "    for p in sorted(docs_path.glob(\"*.pdf\")):\n",
        "        try:\n",
        "            reader = PdfReader(str(p))\n",
        "\n",
        "            # Try empty password if encrypted (common case)\n",
        "            if getattr(reader, \"is_encrypted\", False):\n",
        "                try:\n",
        "                    reader.decrypt(\"\")\n",
        "                except Exception as e:\n",
        "                    skipped.append((p.name, f\"Encrypted (decrypt failed): {e}\"))\n",
        "                    continue\n",
        "\n",
        "            text_parts = []\n",
        "            for page in reader.pages:\n",
        "                t = page.extract_text()\n",
        "                if t:\n",
        "                    text_parts.append(t)\n",
        "\n",
        "            text = \"\\n\".join(text_parts).strip()\n",
        "            if not text:\n",
        "                skipped.append((p.name, \"No extractable text\"))\n",
        "                continue\n",
        "\n",
        "            items.append({\n",
        "                \"doc_id\": p.stem,         # doc1 (no .pdf)\n",
        "                \"source\": str(p),\n",
        "                \"text\": text\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            skipped.append((p.name, str(e)))\n",
        "\n",
        "    return items, skipped\n",
        "\n",
        "documents, skipped = load_pdf_docs(docs_dir)\n",
        "\n",
        "print(\"‚úÖ Loaded docs:\", len(documents))\n",
        "print(\"‚ö†Ô∏è Skipped:\", len(skipped))\n",
        "for name, reason in skipped[:10]:\n",
        "    print(\" -\", name, \"->\", reason)\n",
        "\n",
        "# show keys + one sample like the template does\n",
        "if documents:\n",
        "    print(\"\\nKeys:\", documents[0].keys())\n",
        "    print(\"Example doc_id:\", documents[0][\"doc_id\"])\n",
        "    print(documents[0][\"text\"][:300])\n",
        "else:\n",
        "    raise RuntimeError(\"No PDFs were successfully loaded from ./data/docs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA INGESTION & CHUNKING**"
      ],
      "metadata": {
        "id": "YPlStASgMdGj"
      },
      "id": "YPlStASgMdGj"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Imports\n",
        "import os, re, glob, json, math\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "!pip install PyMuPDF\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3MGWz9mMU6i",
        "outputId": "550496b9-4a08-46ac-e42b-71017ab82a05"
      },
      "id": "X3MGWz9mMU6i",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (1.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"data\"\n",
        "DOC_DIR = os.path.join(DATA_DIR, \"docs\")\n",
        "FIG_DIR = os.path.join(DATA_DIR, \"images\")\n",
        "os.makedirs(DOC_DIR, exist_ok=True)\n",
        "os.makedirs(FIG_DIR, exist_ok=True)\n",
        "\n",
        "pdfs = sorted(glob.glob(os.path.join(DOC_DIR, \"*.pdf\")))\n",
        "imgs = sorted(glob.glob(os.path.join(FIG_DIR, \"*.*\")))\n",
        "\n",
        "print(\"PDFs:\", len(pdfs), pdfs)\n",
        "print(\"Images:\", len(imgs), imgs)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euDrmpblMoGY",
        "outputId": "4076e180-91af-442a-ec4e-c031aeba6cc0"
      },
      "id": "euDrmpblMoGY",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDFs: 5 ['data/docs/doc1.pdf', 'data/docs/doc2.pdf', 'data/docs/doc3.pdf', 'data/docs/doc4.pdf', 'data/docs/doc5.pdf']\n",
            "Images: 10 ['data/images/cyber_kill_chain.png', 'data/images/impact_likelihood_matrix.png', 'data/images/network_system_security.png', 'data/images/nist_framework.png', 'data/images/risk_management.png', 'data/images/risk_management_process.png', 'data/images/security_audit_process.png', 'data/images/soc2_requirements.png', 'data/images/website_security_audit.png', 'data/images/zero_trust.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y tesseract-ocr\n",
        "!pip install -q pytesseract"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJEXer8VM79U",
        "outputId": "63ec4808-15b9-4d5f-a728-75e0a08575d9"
      },
      "id": "mJEXer8VM79U",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Track B (Recommended)\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "@dataclass\n",
        "class TextChunk:\n",
        "    chunk_id: str\n",
        "    doc_id: str\n",
        "    page_num: int\n",
        "    text: str\n",
        "\n",
        "@dataclass\n",
        "class ImageItem:\n",
        "    item_id: str\n",
        "    path: str\n",
        "    caption: str  # simple text to make image retrieval runnable\n",
        "\n",
        "def clean_text(s: str) -> str:\n",
        "    s = s or \"\"\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    return s\n",
        "\n",
        "def extract_pdf_pages(pdf_path: str) -> List[TextChunk]:\n",
        "    doc_id = os.path.basename(pdf_path)\n",
        "    doc = fitz.open(pdf_path)\n",
        "    out: List[TextChunk] = []\n",
        "    for i in range(len(doc)):\n",
        "        page = doc.load_page(i)\n",
        "        text = clean_text(page.get_text(\"text\"))\n",
        "        if text:\n",
        "            out.append(TextChunk(\n",
        "                chunk_id=f\"{doc_id}::p{i+1}\",\n",
        "                doc_id=doc_id,\n",
        "                page_num=i+1,\n",
        "                text=text\n",
        "            ))\n",
        "    return out\n",
        "\n",
        "def load_images_track_b(fig_dir: str) -> List[ImageItem]:\n",
        "    items: List[ImageItem] = []\n",
        "    print(f\"Scanning images in {fig_dir} with OCR...\")\n",
        "\n",
        "    for p in sorted(glob.glob(os.path.join(fig_dir, \"*.*\"))):\n",
        "        base = os.path.basename(p)\n",
        "\n",
        "        # 1. Generate Caption (Filename based)\n",
        "        simple_caption = os.path.splitext(base)[0].replace(\"_\", \" \")\n",
        "\n",
        "        # 2. Run OCR (Tesseract) to get text inside the image\n",
        "        try:\n",
        "            image = Image.open(p)\n",
        "            ocr_text = pytesseract.image_to_string(image).strip()\n",
        "            # Clean up OCR noise (optional)\n",
        "            ocr_text = re.sub(r\"\\s+\", \" \", ocr_text)\n",
        "        except Exception as e:\n",
        "            print(f\"OCR Failed for {base}: {e}\")\n",
        "            ocr_text = \"\"\n",
        "\n",
        "        # 3. Combine for Evidence (Track B Requirement)\n",
        "        # evidence_text = Caption + OCR\n",
        "        final_text = f\"Caption: {simple_caption}. Content: {ocr_text}\"\n",
        "\n",
        "        items.append(ImageItem(item_id=base, path=p, caption=final_text))\n",
        "\n",
        "    return items\n",
        "\n",
        "# Run ingestion\n",
        "page_chunks: List[TextChunk] = []\n",
        "for p in pdfs:\n",
        "    page_chunks.extend(extract_pdf_pages(p))\n",
        "\n",
        "image_items = load_images_track_b(FIG_DIR)\n",
        "\n",
        "print(\"Total text chunks:\", len(page_chunks))\n",
        "print(\"Total images:\", len(image_items))\n",
        "print(\"Sample text chunk:\", page_chunks[0].chunk_id, page_chunks[0].text[:180])\n",
        "print(\"Sample image item:\", image_items[0])\n",
        "\n",
        "# --- Deliverable Output ---\n",
        "\n",
        "print(\"\\n=== Deliverable: Extracted PDF Chunk ===\")\n",
        "if page_chunks:\n",
        "    chunk = page_chunks[0]\n",
        "    print(f\"Chunk ID:   {chunk.chunk_id}\")\n",
        "    print(f\"Source Doc: {chunk.doc_id}\")\n",
        "    print(f\"Page Num:   {chunk.page_num}\")\n",
        "    print(f\"Text Content (First 300 chars):\\n{chunk.text[:300]}...\")\n",
        "else:\n",
        "    print(\"‚ùå No PDF chunks found.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "print(\"\\n=== Deliverable: Extracted Image Evidence ===\")\n",
        "if image_items:\n",
        "    item = image_items[0]\n",
        "    print(f\"Image ID: {item.item_id}\")\n",
        "    print(f\"Path:     {item.path}\")\n",
        "    print(\"-\" * 20)\n",
        "    print(f\"Full Evidence Text (Caption + OCR):\\n{item.caption}\")\n",
        "    # Note: item.caption now holds \"Caption: [filename]. Content: [OCR Text]\"\n",
        "else:\n",
        "    print(\"‚ùå No images found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9o0qHJvNCZK",
        "outputId": "120fc3c8-8d05-49e1-daf5-ee1aa5ca0052"
      },
      "id": "V9o0qHJvNCZK",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning images in data/images with OCR...\n",
            "OCR Failed for security_audit_process.png: Unsupported image format/type\n",
            "Total text chunks: 221\n",
            "Total images: 10\n",
            "Sample text chunk: doc1.pdf::p1 State Data Breach Notification Laws Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team\n",
            "Sample image item: ImageItem(item_id='cyber_kill_chain.png', path='data/images/cyber_kill_chain.png', caption='Caption: cyber kill chain. Content: Harvesting email addresses, conference information, etc. Coupling exploit with backdoor into deliverable payload Delivering weaponized bundle to the victim via email, web, USB, etc. Exploiting a vulnerability to execute code on victim‚Äôs system Installing malware on the asset Command channel for remote manipulation of victim With ‚ÄòHands on Keyboard‚Äô access, intruders accomplish their original goals')\n",
            "\n",
            "=== Deliverable: Extracted PDF Chunk ===\n",
            "Chunk ID:   doc1.pdf::p1\n",
            "Source Doc: doc1.pdf\n",
            "Page Num:   1\n",
            "Text Content (First 300 chars):\n",
            "State Data Breach Notification Laws Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team...\n",
            "\n",
            "============================================================\n",
            "\n",
            "=== Deliverable: Extracted Image Evidence ===\n",
            "Image ID: cyber_kill_chain.png\n",
            "Path:     data/images/cyber_kill_chain.png\n",
            "--------------------\n",
            "Full Evidence Text (Caption + OCR):\n",
            "Caption: cyber kill chain. Content: Harvesting email addresses, conference information, etc. Coupling exploit with backdoor into deliverable payload Delivering weaponized bundle to the victim via email, web, USB, etc. Exploiting a vulnerability to execute code on victim‚Äôs system Installing malware on the asset Command channel for remote manipulation of victim With ‚ÄòHands on Keyboard‚Äô access, intruders accomplish their original goals\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d9b108aa",
      "metadata": {
        "id": "d9b108aa"
      },
      "source": [
        "# 4) Mini Gold Set (Q1‚ÄìQ5) ‚Äî Required\n",
        "\n",
        "Create **5 project-relevant queries** and define a simple evidence rubric.\n",
        "\n",
        "- **Q1‚ÄìQ3:** typical project queries (answerable using evidence)\n",
        "- **Q4:** multimodal evidence query (table/figure heavy, OCR/captions should help)\n",
        "- **Q5:** missing-evidence or ambiguous query (must trigger safe behavior)\n",
        "\n",
        "For each query, define:\n",
        "- `gold_evidence_ids`: list of evidence identifiers that are relevant (doc_id/page/fig id)\n",
        "- `answer_criteria`: 1‚Äì2 bullets\n",
        "- `citation_format`: how you will cite (e.g., `[Doc1 p3]`, `[fig2]`)\n",
        "\n",
        "This enables **consistent evaluation** and makes logging meaningful.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "print(\"PDF docs:\", [p.name for p in Path(\"data/docs\").glob(\"*.pdf\")])\n",
        "print(\"Images:\", [p.name for p in Path(\"data/images\").glob(\"*.png\")])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blggXngxOAlv",
        "outputId": "ca1d1866-a5d8-4e6a-d39f-d5189f43b713"
      },
      "id": "blggXngxOAlv",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF docs: ['doc1.pdf', 'doc2.pdf', 'doc4.pdf', 'doc5.pdf', 'doc3.pdf']\n",
            "Images: ['cyber_kill_chain.png', 'nist_framework.png', 'risk_management.png', 'impact_likelihood_matrix.png', 'zero_trust.png', 'network_system_security.png', 'soc2_requirements.png', 'website_security_audit.png', 'risk_management_process.png', 'security_audit_process.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "c131bc70",
      "metadata": {
        "id": "c131bc70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "635a3ae5-e02b-430b-8b30-400bfb8f705b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  query_id                                           question  \\\n",
              "0       Q1  According to doc1.pdf, what are State Data Bre...   \n",
              "1       Q2  From the cyber_kill_chain.png diagram, list th...   \n",
              "2       Q3  Based on soc2_requirements.png, what are the k...   \n",
              "3       Q4  Using impact_likelihood_matrix.png, which area...   \n",
              "4       Q5                Who won the FIFA World Cup in 2050?   \n",
              "\n",
              "                gold_evidence_ids        query_type  \n",
              "0                      [doc1.pdf]        answerable  \n",
              "1          [cyber_kill_chain.png]        answerable  \n",
              "2         [soc2_requirements.png]        answerable  \n",
              "3  [impact_likelihood_matrix.png]        multimodal  \n",
              "4                              []  missing_evidence  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4b2c351e-8ebd-4496-a20d-4dcb4d30885d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>question</th>\n",
              "      <th>gold_evidence_ids</th>\n",
              "      <th>query_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>According to doc1.pdf, what are State Data Bre...</td>\n",
              "      <td>[doc1.pdf]</td>\n",
              "      <td>answerable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>From the cyber_kill_chain.png diagram, list th...</td>\n",
              "      <td>[cyber_kill_chain.png]</td>\n",
              "      <td>answerable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Based on soc2_requirements.png, what are the k...</td>\n",
              "      <td>[soc2_requirements.png]</td>\n",
              "      <td>answerable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Using impact_likelihood_matrix.png, which area...</td>\n",
              "      <td>[impact_likelihood_matrix.png]</td>\n",
              "      <td>multimodal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Who won the FIFA World Cup in 2050?</td>\n",
              "      <td>[]</td>\n",
              "      <td>missing_evidence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4b2c351e-8ebd-4496-a20d-4dcb4d30885d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4b2c351e-8ebd-4496-a20d-4dcb4d30885d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4b2c351e-8ebd-4496-a20d-4dcb4d30885d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"query_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Q2\",\n          \"Q5\",\n          \"Q3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"From the cyber_kill_chain.png diagram, list the main stages shown in the Cyber Kill Chain in order.\",\n          \"Who won the FIFA World Cup in 2050?\",\n          \"Based on soc2_requirements.png, what are the key SOC 2 Trust Service Criteria categories shown?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold_evidence_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"query_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"answerable\",\n          \"multimodal\",\n          \"missing_evidence\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "MISSING_EVIDENCE_PHRASE = \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "mini_gold = [\n",
        "    {\n",
        "        \"query_id\": \"Q1\",\n",
        "        \"question\": \"According to doc1.pdf, what are State Data Breach Notification Laws and what compliance-based exception(s) are mentioned?\",\n",
        "        \"gold_evidence_ids\": [\"doc1.pdf\"],\n",
        "        \"answer_criteria\": [\n",
        "            \"Defines/describes state data breach notification laws\",\n",
        "            \"Mentions an exception based on compliance with other laws (e.g., HIPAA/GLBA) if stated\",\n",
        "            \"Includes a citation\"\n",
        "        ],\n",
        "        \"citation_format\": \"[doc_id]\",\n",
        "        \"query_type\": \"answerable\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"Q2\",\n",
        "        \"question\": \"From the cyber_kill_chain.png diagram, list the main stages shown in the Cyber Kill Chain in order.\",\n",
        "        \"gold_evidence_ids\": [\"cyber_kill_chain.png\"],\n",
        "        \"answer_criteria\": [\n",
        "            \"Lists the stages shown in the diagram\",\n",
        "            \"Keeps the correct order\",\n",
        "            \"Includes a citation\"\n",
        "        ],\n",
        "        \"citation_format\": \"[evidence_id]\",\n",
        "        \"query_type\": \"answerable\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"Q3\",\n",
        "        \"question\": \"Based on soc2_requirements.png, what are the key SOC 2 Trust Service Criteria categories shown?\",\n",
        "        \"gold_evidence_ids\": [\"soc2_requirements.png\"],\n",
        "        \"answer_criteria\": [\n",
        "            \"Names the categories visible in the image\",\n",
        "            \"Does not invent categories not shown\",\n",
        "            \"Includes a citation\"\n",
        "        ],\n",
        "        \"citation_format\": \"[evidence_id]\",\n",
        "        \"query_type\": \"answerable\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"Q4\",\n",
        "        \"question\": \"Using impact_likelihood_matrix.png, which area represents the highest risk and why?\",\n",
        "        \"gold_evidence_ids\": [\"impact_likelihood_matrix.png\"],\n",
        "        \"answer_criteria\": [\n",
        "            \"Identifies highest risk as the region where both impact and likelihood are highest (or equivalent label)\",\n",
        "            \"Explains using the matrix meaning (risk increases with likelihood and impact)\",\n",
        "            \"Includes a citation\"\n",
        "        ],\n",
        "        \"citation_format\": \"[evidence_id]\",\n",
        "        \"query_type\": \"multimodal\"\n",
        "    },\n",
        "    {\n",
        "        \"query_id\": \"Q5\",\n",
        "        \"question\": \"Who won the FIFA World Cup in 2050?\",\n",
        "        \"gold_evidence_ids\": [],  # ‚úÖ keep as list (type-stable)\n",
        "        \"answer_criteria\": [\n",
        "            f'Returns exactly the missing-evidence phrase: \"{MISSING_EVIDENCE_PHRASE}\"',\n",
        "            \"Does not claim a winner\",\n",
        "            \"Does not cite any evidence\"\n",
        "        ],\n",
        "        \"citation_format\": \"\",\n",
        "        \"query_type\": \"missing_evidence\",\n",
        "        \"expected_safe_answer\": MISSING_EVIDENCE_PHRASE\n",
        "    },\n",
        "]\n",
        "\n",
        "pd.DataFrame(mini_gold)[[\"query_id\", \"question\", \"gold_evidence_ids\", \"query_type\"]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "Rc7GAupjbK43",
      "metadata": {
        "id": "Rc7GAupjbK43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "137ded14-36fb-4f2d-f379-006c43ae5214"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  query_id                                           question  \\\n",
              "0       Q1  According to doc1.pdf, what are State Data Bre...   \n",
              "1       Q2  What are the main stages shown in the Cyber Ki...   \n",
              "2       Q3  What are the SOC 2 Trust Service Criteria cate...   \n",
              "3       Q4  From the impact-likelihood risk matrix, which ...   \n",
              "4       Q5                Who won the FIFA World Cup in 2050?   \n",
              "5       Q6  What are the five core functions shown in the ...   \n",
              "\n",
              "                     gold_evidence_ids  \n",
              "0                           [doc1.pdf]  \n",
              "1          [img::cyber_kill_chain.png]  \n",
              "2         [img::soc2_requirements.png]  \n",
              "3  [img::impact_likelihood_matrix.png]  \n",
              "4                                   []  \n",
              "5            [img::nist_framework.png]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83914df7-49c6-4ed8-9553-7104d24fbcc5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>question</th>\n",
              "      <th>gold_evidence_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>According to doc1.pdf, what are State Data Bre...</td>\n",
              "      <td>[doc1.pdf]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>What are the main stages shown in the Cyber Ki...</td>\n",
              "      <td>[img::cyber_kill_chain.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>What are the SOC 2 Trust Service Criteria cate...</td>\n",
              "      <td>[img::soc2_requirements.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>From the impact-likelihood risk matrix, which ...</td>\n",
              "      <td>[img::impact_likelihood_matrix.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Who won the FIFA World Cup in 2050?</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q6</td>\n",
              "      <td>What are the five core functions shown in the ...</td>\n",
              "      <td>[img::nist_framework.png]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83914df7-49c6-4ed8-9553-7104d24fbcc5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83914df7-49c6-4ed8-9553-7104d24fbcc5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83914df7-49c6-4ed8-9553-7104d24fbcc5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"query_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\",\n          \"What are the main stages shown in the Cyber Kill Chain diagram?\",\n          \"What are the five core functions shown in the NIST Cybersecurity Framework diagram?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold_evidence_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Task: Mini gold set (evidence IDs) for evaluation\n",
        "# Evidence IDs refer to files under ./data/docs or ./data/images\n",
        "# Image evidence uses prefix img::\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "mini_gold = [\n",
        "    {\n",
        "        'query_id': 'Q1',\n",
        "        'question': 'According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?',\n",
        "        'gold_evidence_ids': ['doc1.pdf']\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q2',\n",
        "        'question': 'What are the main stages shown in the Cyber Kill Chain diagram?',\n",
        "        'gold_evidence_ids': ['img::cyber_kill_chain.png']\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q3',\n",
        "        'question': 'What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?',\n",
        "        'gold_evidence_ids': ['img::soc2_requirements.png']\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q4',\n",
        "        'question': 'From the impact-likelihood risk matrix, which area represents the highest risk?',\n",
        "        'gold_evidence_ids': ['img::impact_likelihood_matrix.png']\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q5',\n",
        "        'question': 'Who won the FIFA World Cup in 2050?',\n",
        "        'gold_evidence_ids': []   # Missing-evidence case (must trigger safe behavior)\n",
        "    },\n",
        "    {\n",
        "        'query_id': 'Q6',\n",
        "        'question': 'What are the five core functions shown in the NIST Cybersecurity Framework diagram?',\n",
        "        'gold_evidence_ids': ['img::nist_framework.png']\n",
        "    },\n",
        "]\n",
        "\n",
        "pd.DataFrame(mini_gold)[['query_id','question','gold_evidence_ids']]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6da3e87e",
      "metadata": {
        "id": "6da3e87e"
      },
      "source": [
        "# 5) Retrieval + Answer Function (Reuse Lab 3)\n",
        "\n",
        "Below is a **baseline TF‚ÄëIDF retriever** so this notebook is runnable.\n",
        "Replace with your Lab-3 retrieval stack:\n",
        "- dense (SentenceTransformers + FAISS/Chroma)\n",
        "- sparse (BM25)\n",
        "- hybrid fusion\n",
        "- optional reranking\n",
        "\n",
        "### Required output contract (recommended)\n",
        "Your retrieval function should return a list of evidence items:\n",
        "- `chunk_id` or `doc_id`\n",
        "- `source`\n",
        "- `score`\n",
        "- `citation_tag` (e.g., `[Doc1 p3]`, `[fig2]`)\n",
        "- `text` (the evidence text shown to users)\n",
        "\n",
        "Your answer function must enforce:\n",
        "- **Citations for claims**\n",
        "- If missing evidence: **return exactly**  \n",
        "  `Not enough evidence in the retrieved context.`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "e1f60c59",
      "metadata": {
        "id": "e1f60c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "301e83b9-8804-4098-97ba-f2d233155ad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top evidence: doc1 0.24315996181631225\n",
            "Answer: Based on the retrieved evidence [doc1], the system should ground its response in retrieved context and cite sources. If evidence is missing, it must respond with: 'Not enough evidence in the retrieved context.'. [doc1]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Build a simple TF-IDF index over documents (demo baseline)\n",
        "corpus = [d[\"text\"] for d in documents]\n",
        "doc_ids = [d[\"doc_id\"] for d in documents]\n",
        "sources = [d[\"source\"] for d in documents]\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "def retrieve_tfidf(question: str, top_k: int = 5):\n",
        "    q = vectorizer.transform([question])\n",
        "    sims = cosine_similarity(q, X).ravel()\n",
        "    idxs = np.argsort(-sims)[:top_k]\n",
        "    evidence = []\n",
        "    for rank, i in enumerate(idxs):\n",
        "        evidence.append({\n",
        "            \"chunk_id\": doc_ids[i],\n",
        "            \"source\": sources[i],\n",
        "            \"score\": float(sims[i]),\n",
        "            \"citation_tag\": f\"[{doc_ids[i]}]\",\n",
        "            \"text\": corpus[i][:800]  # truncate for UI\n",
        "        })\n",
        "    return evidence\n",
        "\n",
        "MISSING_EVIDENCE_MSG = \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "def generate_answer_stub(question: str, evidence: list):\n",
        "    \"\"\"Replace with your LLM/VLM generation.\n",
        "    For this template we produce a simple grounded response.\n",
        "    \"\"\"\n",
        "    if not evidence or max(e.get(\"score\", 0.0) for e in evidence) < 0.05:\n",
        "        return MISSING_EVIDENCE_MSG\n",
        "\n",
        "    # Minimal grounded \"answer\" example: summarize top evidence\n",
        "    top = evidence[0]\n",
        "    answer = (\n",
        "        f\"Based on the retrieved evidence {top['citation_tag']}, \"\n",
        "        f\"the system should ground its response in retrieved context and cite sources. \"\n",
        "        f\"If evidence is missing, it must respond with: '{MISSING_EVIDENCE_MSG}'. \"\n",
        "        f\"{top['citation_tag']}\"\n",
        "    )\n",
        "    return answer\n",
        "\n",
        "# Quick test\n",
        "test_q = mini_gold[0][\"question\"]\n",
        "ev = retrieve_tfidf(test_q, top_k=3)\n",
        "print(\"Top evidence:\", ev[0][\"chunk_id\"], ev[0][\"score\"])\n",
        "print(\"Answer:\", generate_answer_stub(test_q, ev))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fixed-size Chunking Strategy (Sliding Window Chunk)**"
      ],
      "metadata": {
        "id": "m-UxevgRPgjm"
      },
      "id": "m-UxevgRPgjm"
    },
    {
      "cell_type": "code",
      "source": [
        "# Chunking knobs (for fixed-size chunking ablation)\n",
        "CHUNK_SIZE    = 900   # characters per chunk\n",
        "CHUNK_OVERLAP = 150   # overlap characters\n",
        "\n",
        "# Reproducibility\n",
        "RANDOM_SEED = 0"
      ],
      "metadata": {
        "id": "XumKw417PmTr"
      },
      "id": "XumKw417PmTr",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_fixed_size_chunks(pdf_path: str, chunk_size=CHUNK_SIZE, overlap=CHUNK_OVERLAP) -> List[TextChunk]:\n",
        "    doc_id = os.path.basename(pdf_path)\n",
        "    doc = fitz.open(pdf_path)\n",
        "    full_text = \"\"\n",
        "    for page in doc:\n",
        "        full_text += clean_text(page.get_text(\"text\")) + \" \"\n",
        "\n",
        "    # Sliding window slicing\n",
        "    chunks = []\n",
        "    for i in range(0, len(full_text), chunk_size - overlap):\n",
        "        window = full_text[i : i + chunk_size]\n",
        "        if len(window) > 50: # Filter tiny chunks\n",
        "            chunks.append(TextChunk(\n",
        "                chunk_id=f\"{doc_id}::span{i}-{i+len(window)}\",\n",
        "                doc_id=doc_id,\n",
        "                page_num=0, # Logical chunk, not page bound\n",
        "                text=window\n",
        "            ))\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "Vceu0t3GPq5w"
      },
      "id": "Vceu0t3GPq5w",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrieval (TF‚ÄëIDF)**\n",
        "We build two TF‚ÄëIDF indexes:\n",
        "\n",
        "- One over **PDF text chunks**\n",
        "- One over **image captions**\n",
        "\n",
        "Retrieval returns the top‚Äëk results with similarity scores."
      ],
      "metadata": {
        "id": "8p3YrwfLQeEE"
      },
      "id": "8p3YrwfLQeEE"
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tfidf_index_text(chunks: List[TextChunk]):\n",
        "    corpus = [c.text for c in chunks]\n",
        "    vec = TfidfVectorizer(lowercase=True, stop_words=\"english\")\n",
        "    X = vec.fit_transform(corpus)\n",
        "    X = normalize(X)\n",
        "    return vec, X\n",
        "\n",
        "def build_tfidf_index_images(items: List[ImageItem]):\n",
        "    corpus = [it.caption for it in items]\n",
        "    vec = TfidfVectorizer(lowercase=True, stop_words=\"english\")\n",
        "    X = vec.fit_transform(corpus)\n",
        "    X = normalize(X)\n",
        "    return vec, X\n",
        "\n",
        "text_vec, text_X = build_tfidf_index_text(page_chunks)\n",
        "img_vec, img_X = build_tfidf_index_images(image_items)\n",
        "\n",
        "def tfidf_retrieve(query: str, vec: TfidfVectorizer, X, top_k: int = 5):\n",
        "    q = vec.transform([query])\n",
        "    q = normalize(q)\n",
        "    scores = (X @ q.T).toarray().ravel()\n",
        "    idx = np.argsort(-scores)[:top_k]\n",
        "    return [(int(i), float(scores[i])) for i in idx]\n",
        "\n",
        "print(\"‚úÖ Indexes built.\")\n",
        "\n",
        "# Inspect built indexes by listing first 5 as a sample\n",
        "print(f\"--- Text Index ({len(page_chunks)} items) ---\")\n",
        "for i, chunk in enumerate(page_chunks[:5]):  # Print first 5 as a sample\n",
        "    # Assuming 'chunk' has a 'source_doc' or similar attribute, otherwise just print text\n",
        "    preview = chunk.text[:50].replace(\"\\n\", \" \") + \"...\"\n",
        "    print(f\"ID {i}: {preview}\")\n",
        "\n",
        "print(f\"\\n--- Image Index ({len(image_items)} items) ---\")\n",
        "for i, item in enumerate(image_items[:5]):\n",
        "    print(f\"ID {i}: {item.caption} (File: {item.item_id})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0UUwRLeQtsz",
        "outputId": "8e11856f-89bc-4c04-c2a7-de5b8810d34a"
      },
      "id": "P0UUwRLeQtsz",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Indexes built.\n",
            "--- Text Index (221 items) ---\n",
            "ID 0: State Data Breach Notification Laws Prepared by Fo...\n",
            "ID 1: FOR INFORMATIONAL PURPOSES ONLY 4824-6127-3219.41 ...\n",
            "ID 2: FOR INFORMATIONAL PURPOSES ONLY 4824-6127-3219.41 ...\n",
            "ID 3: 3 Return to Map FOR INFORMATIONAL PURPOSES ONLY 48...\n",
            "ID 4: 4 Return to Map FOR INFORMATIONAL PURPOSES ONLY 48...\n",
            "\n",
            "--- Image Index (10 items) ---\n",
            "ID 0: Caption: cyber kill chain. Content: Harvesting email addresses, conference information, etc. Coupling exploit with backdoor into deliverable payload Delivering weaponized bundle to the victim via email, web, USB, etc. Exploiting a vulnerability to execute code on victim‚Äôs system Installing malware on the asset Command channel for remote manipulation of victim With ‚ÄòHands on Keyboard‚Äô access, intruders accomplish their original goals (File: cyber_kill_chain.png)\n",
            "ID 1: Caption: impact likelihood matrix. Content: Catastrophic Significant Ss Moderate D ler a + low Negligable Catastrophic | Stop 1 2 3 4 Unacceptable Urgent Action 2 3 8 ea Undesirable Action $ S go zg Acceptable | Monitor Z 2 ¬∞ Desirable | | No Action Likelihood quenbaly U1 (File: impact_likelihood_matrix.png)\n",
            "ID 2: Caption: network system security. Content: Security ral Consulting Threat &Risk Assessment Vulnerability Assessment Security Control Selection Incident Response (File: network_system_security.png)\n",
            "ID 3: Caption: nist framework. Content: NIST Cybersecurity Framework Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua Duis aute irure dolor in reprehenderit in voluptate velit esse sed do Protect Respond Elements in the subjects that Elements in the subjects that have some purposes & goals have some purposes & goals for the business company for the business company 01 ¬• 02 ¬•03 ¬• 04 Y¬• 05 Identify Detect Recover Elements in the subjects that Elements in the subjects that Elements in the subjects that have some purposes & goals have some purposes & goals have some purposes & goals for the business company for the business company for the business company (File: nist_framework.png)\n",
            "ID 4: Caption: risk management. Content: [ IDENTIFY | | [ANALYZE SSK CE ff [eontRoL (File: risk_management.png)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build Dense Retrieval and Figure Index**"
      ],
      "metadata": {
        "id": "uKRZiVuvQ60C"
      },
      "id": "uKRZiVuvQ60C"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q sentence-transformers\n",
        "!pip install -q sentence-transformers faiss-cpu"
      ],
      "metadata": {
        "id": "iRZ2DbU6Q9FK"
      },
      "id": "iRZ2DbU6Q9FK",
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Retrieval knobs\n",
        "TOP_K_TEXT     = 5    # candidate text chunks\n",
        "TOP_K_IMAGES   = 3    # candidate images (based on captions/filenames)\n",
        "TOP_K_EVIDENCE = 8    # final evidence items used in the context"
      ],
      "metadata": {
        "id": "jbbrEDvfRG6e"
      },
      "id": "jbbrEDvfRG6e",
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Create embeddings\n",
        "corpus_text = [c.text for c in page_chunks]\n",
        "# Remove convert_to_tensor=True so we get a NumPy array for FAISS\n",
        "corpus_embeddings = model.encode(corpus_text)\n",
        "\n",
        "# Build FAISS Index\n",
        "d = corpus_embeddings.shape[1]  # Dimension of embeddings (e.g., 384)\n",
        "index_dense = faiss.IndexFlatL2(d) # L2 distance (Euclidean)\n",
        "index_dense.add(corpus_embeddings)\n",
        "\n",
        "print(f\"‚úÖ Dense Index built with {index_dense.ntotal} vectors.\")\n",
        "\n",
        "# Embed the captions from your image_items list\n",
        "corpus_caption = [item.caption for item in image_items]\n",
        "caption_embeddings = model.encode(corpus_caption, convert_to_tensor=False)\n",
        "\n",
        "# Build FAISS Index for Image Captions\n",
        "d_cap = caption_embeddings.shape[1] # Dimension = 384\n",
        "index_captions = faiss.IndexFlatL2(d_cap)\n",
        "index_captions.add(caption_embeddings)\n",
        "\n",
        "print(f\"‚úÖ Approach 1 (Captions): Indexed {index_captions.ntotal} images via text.\")\n",
        "\n",
        "def dense_retrieve(query, top_k=TOP_K_TEXT):\n",
        "    # Encode query to numpy. Wrap in list [query] to ensure (1, d) shape.\n",
        "    query_emb = model.encode([query])\n",
        "\n",
        "    # Search FAISS\n",
        "    distances, indices = index_dense.search(query_emb, top_k)\n",
        "\n",
        "    # Return indices\n",
        "    return [(int(idx), float(dist)) for idx, dist in zip(indices[0], distances[0])]\n",
        "\n",
        "def retrieve_images_by_caption(query: str, top_k=TOP_K_IMAGES):\n",
        "    # Embed query using the SAME text model\n",
        "    q_emb = model.encode([query])\n",
        "    distances, indices = index_captions.search(q_emb, top_k)\n",
        "\n",
        "    # Return matched ImageItems\n",
        "    results = []\n",
        "    for idx, dist in zip(indices[0], distances[0]):\n",
        "        if idx < 0: continue # FAISS returns -1 if not found\n",
        "        results.append((image_items[idx], float(dist)))\n",
        "    return results\n",
        "\n",
        "# Validation by checking vocabulary size\n",
        "print(f\"Text Dictionary Size: {len(text_vec.vocabulary_)}\")\n",
        "print(f\"Image Dictionary Size: {len(img_vec.vocabulary_)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "275735636e1e404ca63dd80cb571ab34",
            "22f48da85fd74cb7ac808a5f3f04c1f9",
            "2a4d43663ee0465387a20b2fbcacf7a3",
            "51e734f2fa4b463b87c4e29aeb341b79",
            "0df2f653542c43309ad2ef1cd3ca8858",
            "6e4cb615c9fc4c95a71c594322b9127c",
            "55eee262fe3d4bef853aaffd304d57b2",
            "d1fc65f206c84014b1db0543f01becd0",
            "1a0f227f2e9f4a149d48a39578341af4",
            "0a232016ed914045b38c2c2770f0f780",
            "e0c202b989c74cf69b581caa87abfd7b"
          ]
        },
        "id": "VUGC-uMIRI0e",
        "outputId": "6919764a-19f8-4798-89ba-3be80c5f2201"
      },
      "id": "VUGC-uMIRI0e",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "275735636e1e404ca63dd80cb571ab34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dense Index built with 221 vectors.\n",
            "‚úÖ Approach 1 (Captions): Indexed 10 images via text.\n",
            "Text Dictionary Size: 4906\n",
            "Image Dictionary Size: 201\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build evidence context**\n",
        "We assemble a compact context string + list of image paths.\n",
        "\n",
        "**Guidelines for good context:**\n",
        "\n",
        "- Keep snippets short (100‚Äì300 chars)\n",
        "- Always include chunk IDs so you can cite evidence\n",
        "- Attach images that are likely relevant"
      ],
      "metadata": {
        "id": "5V-cAFFXRkCU"
      },
      "id": "5V-cAFFXRkCU"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Fusion / retrieval hyperparameters ---\n",
        "TOP_K_TEXT = 5\n",
        "TOP_K_IMAGES = 3\n",
        "TOP_K_EVIDENCE = 5\n",
        "ALPHA = 0.6   # 0.5 = balanced, >0.5 favors text, <0.5 favors images\n"
      ],
      "metadata": {
        "id": "0OxS7sbjSEEH"
      },
      "id": "0OxS7sbjSEEH",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _normalize_scores(pairs):\n",
        "    \"\"\"Min-max normalize a list of (idx, score) to [0,1].\n",
        "    If all scores equal, returns 1.0 for each item (so ordering stays stable).\n",
        "    \"\"\"\n",
        "    if not pairs:\n",
        "        return []\n",
        "    scores = [s for _, s in pairs]\n",
        "    lo, hi = min(scores), max(scores)\n",
        "    if abs(hi - lo) < 1e-12:\n",
        "        return [(i, 1.0) for i, _ in pairs]\n",
        "    return [(i, (s - lo) / (hi - lo)) for i, s in pairs]\n",
        "\n",
        "\n",
        "def build_context(\n",
        "    question: str,\n",
        "    top_k_text: int = TOP_K_TEXT,\n",
        "    top_k_images: int = TOP_K_IMAGES,\n",
        "    top_k_evidence: int = TOP_K_EVIDENCE,\n",
        "    alpha: float = ALPHA,\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"Build a multimodal context block for the question.\n",
        "\n",
        "    Students:\n",
        "    - `top_k_text` / `top_k_images` control *candidate retrieval* per modality.\n",
        "    - `top_k_evidence` controls the *final context size*.\n",
        "    - `alpha` controls fusion: higher = prefer text evidence, lower = prefer images.\n",
        "\n",
        "    This function returns:\n",
        "    - `context`: a text block with the selected evidence (what you pass to an LLM)\n",
        "    - `image_paths`: paths of images selected as evidence\n",
        "    - `evidence`: structured evidence list (recommended for your report)\n",
        "    \"\"\"\n",
        "    # 1) Retrieve candidates from each modality\n",
        "    text_hits = tfidf_retrieve(question, text_vec, text_X, top_k=top_k_text)   # [(idx, score), ...]\n",
        "    img_hits  = tfidf_retrieve(question, img_vec,  img_X,  top_k=top_k_images)\n",
        "\n",
        "    # 2) Normalize scores per modality and fuse with ALPHA\n",
        "    text_norm = _normalize_scores(text_hits)\n",
        "    img_norm  = _normalize_scores(img_hits)\n",
        "\n",
        "    fused = []\n",
        "    for idx, s in text_norm:\n",
        "        ch = page_chunks[idx]\n",
        "        fused.append({\n",
        "            \"modality\": \"text\",\n",
        "            \"id\": ch.chunk_id,\n",
        "            \"raw_score\": float(dict(text_hits).get(idx, 0.0)),\n",
        "            \"fused_score\": float(alpha * s),\n",
        "            \"text\": ch.text,\n",
        "            \"path\": None,\n",
        "        })\n",
        "\n",
        "    for idx, s in img_norm:\n",
        "        it = image_items[idx]\n",
        "        fused.append({\n",
        "            \"modality\": \"image\",\n",
        "            \"id\": it.item_id,\n",
        "            \"raw_score\": float(dict(img_hits).get(idx, 0.0)),\n",
        "            \"fused_score\": float((1.0 - alpha) * s),\n",
        "            \"text\": it.caption,     # we retrieve on caption/filename text\n",
        "            \"path\": it.path,\n",
        "        })\n",
        "\n",
        "    # 3) Pick top fused evidence\n",
        "    fused = sorted(fused, key=lambda d: d[\"fused_score\"], reverse=True)[:top_k_evidence]\n",
        "\n",
        "    # 4) Build the context string (what you feed into a generator/LLM)\n",
        "    ctx_lines = []\n",
        "    image_paths = []\n",
        "    for ev in fused:\n",
        "        if ev[\"modality\"] == \"text\":\n",
        "            snippet = (ev[\"text\"] or \"\")[:260].replace(\"\\n\", \" \")\n",
        "            ctx_lines.append(f\"[TEXT | {ev['id']} | fused={ev['fused_score']:.3f}] {snippet}\")\n",
        "        else:\n",
        "            ctx_lines.append(f\"[IMAGE | {ev['id']} | fused={ev['fused_score']:.3f}] caption={ev['text']}\")\n",
        "            image_paths.append(ev[\"path\"])\n",
        "\n",
        "    return {\n",
        "        \"question\": question,\n",
        "        \"context\": \"\\n\".join(ctx_lines),\n",
        "        \"image_paths\": image_paths,\n",
        "        \"text_hits\": text_hits,\n",
        "        \"img_hits\": img_hits,\n",
        "        \"evidence\": fused,\n",
        "        \"alpha\": alpha,\n",
        "        \"top_k_text\": top_k_text,\n",
        "        \"top_k_images\": top_k_images,\n",
        "        \"top_k_evidence\": top_k_evidence,\n",
        "    }\n",
        "\n",
        "\n",
        "# --- Demo: what retrieval returns for one query ---\n",
        "ctx_demo = build_context(mini_gold[0][\"question\"])\n",
        "print(ctx_demo[\"context\"])\n",
        "print(\"Images:\", ctx_demo[\"image_paths\"])\n",
        "print(\"Fusion alpha:\", ctx_demo[\"alpha\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-fSpR34Rx4E",
        "outputId": "da858fcf-8455-4261-98a3-e396d607d144"
      },
      "id": "Z-fSpR34Rx4E",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TEXT | doc1.pdf::p1 | fused=0.600] State Data Breach Notification Laws Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team\n",
            "[IMAGE | zero_trust.png | fused=0.400] caption=Caption: zero trust. Content: Identity Network Endpoints Infrastructure Data Applications\n",
            "[TEXT | doc1.pdf::p35 | fused=0.068] 34 Return to Map FOR INFORMATIONAL PURPOSES ONLY 4824-6127-3219.41 State of Residence Maine Statute 10 Me. Rev. Stat. ¬ß 1346 et seq. Definition of ‚ÄúPersonal Information‚Äù (A) An individual‚Äôs first name or initial and last name in combination with any one or mor\n",
            "[TEXT | doc1.pdf::p2 | fused=0.063] FOR INFORMATIONAL PURPOSES ONLY 4824-6127-3219.41 1 ‚ñ†Exceptions based on compliance with other laws, such as the Health Insurance Portability and Accountability Act (HIPAA) or Gramm-Leach-Bliley Act (GLBA). ‚ñ†Exceptions regarding good faith acquisition of perso\n",
            "[TEXT | doc1.pdf::p27 | fused=0.033] 26 Return to Map FOR INFORMATIONAL PURPOSES ONLY 4824-6127-3219.41 State of Residence Illinois Statute 815 Ill. Comp. Stat. 530/5 et seq. Definition of ‚ÄúPersonal Information‚Äù (A) An individual‚Äôs first name or first initial and last name in combination with any\n",
            "Images: ['data/images/zero_trust.png']\n",
            "Fusion alpha: 0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reranking**"
      ],
      "metadata": {
        "id": "v636mCk6SUzq"
      },
      "id": "v636mCk6SUzq"
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import CrossEncoder\n",
        "\n",
        "# Load a standard reranking model (trained on MS MARCO)\n",
        "# This model outputs a score (higher is better, usually unbounded but often -10 to 10)\n",
        "print(\"Loading Reranker...\")\n",
        "reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
        "print(\"‚úÖ Reranker loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "dae3e14c8f144fe3a17a3a476ca21324",
            "5ab15182f96f4e9e90f3abad58446023",
            "f48cd491e986400197afc8db59574cc6",
            "56ab3f061dd24cd0a7048b613918c007",
            "99d5a08f625a47a8a488e1d8823aa277",
            "a5172eefb0dd4939a0901db8093f33e8",
            "65858356adc44fbaa9feba34102af832",
            "858d2fbcc3fd4db5857ad0de2553bb44",
            "5f98110bbb17403d8929a1634a1c81c8",
            "40e87106195745da864b32752dde1cd3",
            "0bed16b0a890433898a4a23cd79de160"
          ]
        },
        "id": "RO1exXSkSWSw",
        "outputId": "6e7ae6b7-c526-457e-bee3-1a6e8b5963d9"
      },
      "id": "RO1exXSkSWSw",
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Reranker...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/105 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dae3e14c8f144fe3a17a3a476ca21324"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "BertForSequenceClassification LOAD REPORT from: cross-encoder/ms-marco-MiniLM-L-6-v2\n",
            "Key                          | Status     |  | \n",
            "-----------------------------+------------+--+-\n",
            "bert.embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Reranker loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_scores(hits):\n",
        "    \"\"\"Normalizes a list of (idx, score) to 0..1 range.\"\"\"\n",
        "    if not hits: return []\n",
        "    scores = [s for _, s in hits]\n",
        "    min_s, max_s = min(scores), max(scores)\n",
        "    if max_s == min_s: return [(i, 1.0) for i, _ in hits]\n",
        "    return [(i, (s - min_s) / (max_s - min_s)) for i, s in hits]\n",
        "\n",
        "def get_retrieval_results(query: str, method: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Retrieves candidate chunks based on the specified method.\n",
        "    Returns a list of (chunk_index, score).\n",
        "    \"\"\"\n",
        "    # 1. SPARSE ONLY\n",
        "    if method == \"Sparse Only\":\n",
        "        return tfidf_retrieve(query, text_vec, text_X, top_k=top_k)\n",
        "\n",
        "    # 2. DENSE ONLY\n",
        "    if method == \"Dense Only\":\n",
        "        # Assumes dense_retrieve exists from previous step\n",
        "        return dense_retrieve(query, top_k=top_k)\n",
        "\n",
        "    # 3. HYBRID (Sparse + Dense)\n",
        "    if method == \"Hybrid\" or method == \"Hybrid + Rerank\" or method == \"Multimodal\":\n",
        "        # Retrieve more candidates (e.g., top_k * 2) from both to ensure overlap\n",
        "        sparse_hits = tfidf_retrieve(query, text_vec, text_X, top_k=top_k*2)\n",
        "        dense_hits = dense_retrieve(query, top_k=top_k*2)\n",
        "\n",
        "        # Create a dict to fuse scores: {idx: fused_score}\n",
        "        fusion_map = {}\n",
        "\n",
        "        # Normalize and weigh (Alpha=0.5 usually works well for Hybrid)\n",
        "        for idx, score in normalize_scores(sparse_hits):\n",
        "            fusion_map[idx] = fusion_map.get(idx, 0) + (0.5 * score)\n",
        "\n",
        "        for idx, score in normalize_scores(dense_hits):\n",
        "            fusion_map[idx] = fusion_map.get(idx, 0) + (0.5 * score)\n",
        "\n",
        "        # Sort by fused score\n",
        "        hybrid_results = sorted(fusion_map.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # If just Hybrid, return top_k\n",
        "        if method == \"Hybrid\":\n",
        "            return hybrid_results[:top_k]\n",
        "\n",
        "        # 4. RERANKING (Re-score the hybrid candidates)\n",
        "        # We take the top 20 hybrid candidates and rerank them\n",
        "        candidates = hybrid_results[:20]\n",
        "\n",
        "        # Prepare pairs for CrossEncoder: [[query, doc_text], ...]\n",
        "        pairs = []\n",
        "        for idx, _ in candidates:\n",
        "            pairs.append([query, page_chunks[idx].text])\n",
        "\n",
        "        # Predict scores\n",
        "        rerank_scores = reranker.predict(pairs)\n",
        "\n",
        "        # Attach new scores to indices\n",
        "        reranked_results = []\n",
        "        for i, (idx, _) in enumerate(candidates):\n",
        "            reranked_results.append((idx, float(rerank_scores[i])))\n",
        "\n",
        "        # Sort by new reranker score\n",
        "        final_ranked = sorted(reranked_results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        return final_ranked[:top_k]\n",
        "\n",
        "    return []"
      ],
      "metadata": {
        "id": "2aeln-s1Sdld"
      },
      "id": "2aeln-s1Sdld",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚ÄúGenerator‚Äù (simple, offline)**\n",
        "To keep this notebook runnable anywhere, we implement **a lightweight extractive generator**:\n",
        "\n",
        "- It returns the top evidence lines\n",
        "- In addition , we implement LLM Call with HF local model\n",
        "- LLM call with API"
      ],
      "metadata": {
        "id": "HypDPKvCSje8"
      },
      "id": "HypDPKvCSje8"
    },
    {
      "cell_type": "code",
      "source": [
        "# Fusion knob (text vs images)\n",
        "ALPHA = 0.5  # 0.0 = images dominate, 1.0 = text dominates\n",
        ""
      ],
      "metadata": {
        "id": "O0zzNvYwSswe"
      },
      "id": "O0zzNvYwSswe",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 1: Lightweight extractive generator\n",
        "\n",
        "def simple_extractive_answer(question: str, context: str) -> str:\n",
        "    lines = context.splitlines()\n",
        "    if not lines:\n",
        "        return \"I don't know (no evidence retrieved).\"\n",
        "    # Return top 2 evidence lines as a \"grounded\" answer\n",
        "    return (\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        \"Grounded answer (extractive):\\n\"\n",
        "        + \"\\n\".join(lines[:2])\n",
        "    )\n",
        "\n",
        "def run_query(qobj, top_k_text=TOP_K_TEXT, top_k_images=TOP_K_IMAGES, top_k_evidence=TOP_K_EVIDENCE, alpha=ALPHA) -> Dict[str, Any]:\n",
        "    question = qobj[\"question\"]\n",
        "    ctx = build_context(question, top_k_text=top_k_text, top_k_images=top_k_images, top_k_evidence=top_k_evidence, alpha=alpha)\n",
        "    answer = simple_extractive_answer(question, ctx[\"context\"])\n",
        "    return {\n",
        "        \"id\": qobj[\"query_id\"], # Fixed: changed from \"id\" to \"query_id\"\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context\": ctx[\"context\"],\n",
        "        \"image_paths\": ctx[\"image_paths\"],\n",
        "        \"text_hits\": ctx[\"text_hits\"],\n",
        "        \"img_hits\": ctx[\"img_hits\"],\n",
        "    }\n",
        "\n",
        "results = [run_query(q) for q in mini_gold]\n",
        "for r in results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(r[\"id\"], r[\"question\"])\n",
        "    print(r[\"answer\"][:500])\n",
        "    print(\"Images:\", [os.path.basename(p) for p in r[\"image_paths\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrilEgoISwW7",
        "outputId": "4b9b3d06-89c9-4003-8897-cbd237b762de"
      },
      "id": "MrilEgoISwW7",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q1 According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\n",
            "Question: According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc1.pdf::p1 | fused=0.500] State Data Breach Notification Laws Prepared by Foley‚Äôs Cybersecurity & Data Privacy Team\n",
            "[IMAGE | zero_trust.png | fused=0.500] caption=Caption: zero trust. Content: Identity Network Endpoints Infrastructure Data Applications\n",
            "Images: ['zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "Q2 What are the main stages shown in the Cyber Kill Chain diagram?\n",
            "Question: What are the main stages shown in the Cyber Kill Chain diagram?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc4.pdf::p42 | fused=0.500] 42 will require changes to thresholds in risk acceptance, transference, and new mechanisms for mitigation. Supply Chain Security (New in v2) The security of a system is only as good as the supply chain that it relies on. Defending the supply chain requires sec\n",
            "[IMAGE | cyber_kill_chain.png | fused=0.500] caption=Caption: cyber kill chain. Content: Harvesti\n",
            "Images: ['cyber_kill_chain.png']\n",
            "\n",
            "================================================================================\n",
            "Q3 What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?\n",
            "Question: What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc5.pdf::p1 | fused=0.500] System and Organization Controls (SOC) 2 Type II Report on Management's Description of Provectus Report on Controls Placed in Operation and Test of Operating Effectiveness Relevant to the Trust Services Criteria for Security Category For the Period April 19, 2\n",
            "[IMAGE | soc2_requirements.png | fused=0.500] caption=Caption: soc2 requirements.\n",
            "Images: ['soc2_requirements.png', 'zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "Q4 From the impact-likelihood risk matrix, which area represents the highest risk?\n",
            "Question: From the impact-likelihood risk matrix, which area represents the highest risk?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc3.pdf::p17 | fused=0.500] NIST CSWP 29 The NIST Cybersecurity Framework (CSF) 2.0 February 26, 2024 12 organizations by their nature may monitor risk at the enterprise level, while larger companies may maintain separate risk management efforts integrated into the ERM. Organizations can\n",
            "[IMAGE | risk_management_process.png | fused=0.500] caption=Caption: risk managem\n",
            "Images: ['risk_management_process.png', 'impact_likelihood_matrix.png']\n",
            "\n",
            "================================================================================\n",
            "Q5 Who won the FIFA World Cup in 2050?\n",
            "Question: Who won the FIFA World Cup in 2050?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc3.pdf::p3 | fused=0.500] NIST CSWP 29 The NIST Cybersecurity Framework (CSF) 2.0 February 26, 2024 ii Acknowledgments The CSF is the result of a multi-year collaborative effort across industry, academia, and government in the United States and around the world. NIST acknowledges and t\n",
            "[IMAGE | cyber_kill_chain.png | fused=0.500] caption=Caption: cyber kill chain. Content: Harvesting email addresses, conferenc\n",
            "Images: ['cyber_kill_chain.png', 'impact_likelihood_matrix.png', 'network_system_security.png']\n",
            "\n",
            "================================================================================\n",
            "Q6 What are the five core functions shown in the NIST Cybersecurity Framework diagram?\n",
            "Question: What are the five core functions shown in the NIST Cybersecurity Framework diagram?\n",
            "\n",
            "Grounded answer (extractive):\n",
            "[TEXT | doc3.pdf::p8 | fused=0.500] NIST CSWP 29 The NIST Cybersecurity Framework (CSF) 2.0 February 26, 2024 3 2. Introduction to the CSF Core Appendix A is the CSF Core ‚Äî a set of cybersecurity outcomes arranged by Function, then Category, and finally Subcategory, as depicted in Fig. 1. These \n",
            "[IMAGE | nist_framework.png | fused=0.500] caption=Caption: nist framework. Co\n",
            "Images: ['nist_framework.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generator using LLM (API Call) with model gemini-2.5-flash**"
      ],
      "metadata": {
        "id": "wd_60GT8S0nZ"
      },
      "id": "wd_60GT8S0nZ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 2: LLM extractive generator (API Call)\n",
        "\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# --- SETUP LLM ---\n",
        "# Set up secret key on the left side bar\n",
        "try:\n",
        "    api_key = userdata.get('GEMINI_API_KEY')\n",
        "except Exception:\n",
        "    api_key = \"PASTE_YOUR_KEY_HERE\"\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = api_key\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "def generate_llm_answer(question: str, context: str) -> str:\n",
        "    \"\"\"Generates an answer using an LLM (Gemini) based on the provided context.\"\"\"\n",
        "\n",
        "    # 1. Check for empty context\n",
        "    if not context or not context.strip():\n",
        "        return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "    # 2. Define the model\n",
        "    # Using gemini-2.5-flash as it is widely available and free-tier friendly\n",
        "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "    # 3. Construct the prompt\n",
        "    prompt = f\"\"\"\n",
        "    You are a helpful assistant for a Multimodal RAG system.\n",
        "    Use the following retrieved context (text chunks and image descriptions) to answer the user's question.\n",
        "\n",
        "    RULES:\n",
        "    1. Answer ONLY using the provided context. If the answer is not in the context, say \"Not enough evidence in the retrieved context.\"\n",
        "    2. Cite your sources! When you use information, append the source ID like [TEXT | doc1.pdf::p1] or [IMAGE | figure1.png].\n",
        "    3. Be concise and direct.\n",
        "\n",
        "    CONTEXT:\n",
        "    {context}\n",
        "\n",
        "    QUESTION:\n",
        "    {question}\n",
        "\n",
        "    ANSWER:\n",
        "    \"\"\"\n",
        "\n",
        "    # 4. Call the API\n",
        "    try:\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"LLM Generation Error: {str(e)} (Check your API Key)\"\n",
        "\n",
        "# --- UPDATED RUN_QUERY ---\n",
        "def run_query(qobj, top_k_text=TOP_K_TEXT, top_k_images=TOP_K_IMAGES, top_k_evidence=TOP_K_EVIDENCE, alpha=ALPHA) -> Dict[str, Any]:\n",
        "    question = qobj[\"question\"]\n",
        "\n",
        "    # 1. Retrieve and Build Context\n",
        "    ctx = build_context(question, top_k_text=top_k_text, top_k_images=top_k_images, top_k_evidence=top_k_evidence, alpha=alpha)\n",
        "\n",
        "    # 2. Generate Answer with LLM (Replaces simple_extractive_answer)\n",
        "    answer = generate_llm_answer(question, ctx[\"context\"])\n",
        "\n",
        "    return {\n",
        "        \"id\": qobj[\"query_id\"],\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context\": ctx[\"context\"],\n",
        "        \"image_paths\": ctx[\"image_paths\"],\n",
        "        \"text_hits\": ctx[\"text_hits\"],\n",
        "        \"img_hits\": ctx[\"img_hits\"],\n",
        "    }\n",
        "\n",
        "# --- EXECUTION ---\n",
        "results = [run_query(q) for q in mini_gold]\n",
        "\n",
        "for r in results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"[{r['id']}] Question: {r['question']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"LLM Answer:\\n{r['answer']}\")\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Context Images:\", [os.path.basename(p) for p in r[\"image_paths\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        },
        "id": "as4FwvgvS7cO",
        "outputId": "c453b308-9783-4195-d20f-9cc313c33cfd"
      },
      "id": "as4FwvgvS7cO",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 542.59ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 269.95ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 245.05ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 430.80ms\n",
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 360.21ms\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "[Q1] Question: According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "[Q2] Question: What are the main stages shown in the Cyber Kill Chain diagram?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['cyber_kill_chain.png']\n",
            "\n",
            "================================================================================\n",
            "[Q3] Question: What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['soc2_requirements.png', 'zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "[Q4] Question: From the impact-likelihood risk matrix, which area represents the highest risk?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['risk_management_process.png', 'impact_likelihood_matrix.png']\n",
            "\n",
            "================================================================================\n",
            "[Q5] Question: Who won the FIFA World Cup in 2050?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['cyber_kill_chain.png', 'impact_likelihood_matrix.png', 'network_system_security.png']\n",
            "\n",
            "================================================================================\n",
            "[Q6] Question: What are the five core functions shown in the NIST Cybersecurity Framework diagram?\n",
            "--------------------------------------------------------------------------------\n",
            "LLM Answer:\n",
            "LLM Generation Error: 400 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: API key not valid. Please pass a valid API key. (Check your API Key)\n",
            "--------------------------------------------------------------------------------\n",
            "Context Images: ['nist_framework.png']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:400 POST /v1beta/models/gemini-2.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (::1) 243.70ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generator using HuggingFace LLM (local) with flan-t5-large**"
      ],
      "metadata": {
        "id": "Mb7fFSDnTA81"
      },
      "id": "Mb7fFSDnTA81"
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q transformers accelerate bitsandbytes"
      ],
      "metadata": {
        "id": "rtIaY57ZTDrZ"
      },
      "id": "rtIaY57ZTDrZ",
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 3: HuggingFace Local\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the local model (for extractive RAG)\n",
        "print(\"Loading local model...\")\n",
        "llm_pipeline = pipeline(\n",
        "    \"text-generation\",\n",
        "    # model=\"google/flan-t5-large\",\n",
        "    model = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
        ")\n",
        "print(\"‚úÖ Model loaded.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "9f4d4229dc44457198c368d7578f22fa",
            "427ceeb313e0446483ca1b79f879f6ea",
            "9656b0b6f7e84d3098d8614d115f4f48",
            "ac1abafcf62044ab90d2ce4a91495307",
            "08c6349ac3c14f868351a58115da9bc0",
            "dc8b237ab4cf4198b3f3c78e5c5ba057",
            "ac47f5caf8424454a8abb3b7dcd59d58",
            "795933a588404cd7b0959509dbbe95a8",
            "1509904b35c244569846176b45737247",
            "ebbef4a5eac84b20832f36ae9362ce94",
            "8f7ad8effb4642d69b3f83efc3beb2b1"
          ]
        },
        "id": "ZnXJJ_IqTJBd",
        "outputId": "2ac143be-d0c6-4fea-fa9b-2612e4c8df87"
      },
      "id": "ZnXJJ_IqTJBd",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading local model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading weights:   0%|          | 0/201 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f4d4229dc44457198c368d7578f22fa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Model loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def llm_extractive_answer(question: str, context: str) -> str:\n",
        "    \"\"\"\n",
        "    Replaces simple_extractive_answer with a local LLM generation.\n",
        "    \"\"\"\n",
        "    if not context or not context.strip():\n",
        "        return \"I don't know (no evidence retrieved).\"\n",
        "\n",
        "    tokenizer = llm_pipeline.tokenizer # Access tokenizer from the pipeline\n",
        "    max_context_tokens = 1500 # Safe limit (2048 total - 400 new - ~148 buffer)\n",
        "\n",
        "    # Tokenize the context\n",
        "    tokenized_context = tokenizer(context, truncation=False, return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "    # If context is too long, slice it\n",
        "    if tokenized_context.shape[1] > max_context_tokens:\n",
        "        # Keep the first 1500 tokens\n",
        "        tokenized_context = tokenized_context[:, :max_context_tokens]\n",
        "        # Decode back to string\n",
        "        context = tokenizer.decode(tokenized_context[0], skip_special_tokens=True)\n",
        "\n",
        "    # Prompt engineering\n",
        "    # Note: For TinyLlama, a simple format works, but we add \"Answer:\" to trigger the generation.\n",
        "    prompt = (\n",
        "        f\"Use the Context below to answer the Question. \"\n",
        "        f\"If the answer is not in the Context, say 'Not enough evidence in the retrieved context.'.\\n\\n\"\n",
        "        f\"Context:\\n{context}\\n\\n\"\n",
        "        f\"Question: {question}\"\n",
        "        f\"\\n\\nAnswer:\"\n",
        "    )\n",
        "\n",
        "    # Generate\n",
        "    # FIXED: Increased max_new_tokens to 400 (prevents cut-offs)\n",
        "    # FIXED: Set do_sample=True (prevents the \"1.1.1.1\" repetition loop)\n",
        "    output = llm_pipeline(\n",
        "        prompt,\n",
        "        max_new_tokens=400,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        return_full_text=False\n",
        "    )\n",
        "    generated_text = output[0]['generated_text'].strip()\n",
        "\n",
        "    return (\n",
        "        f\"Question: {question}\\n\\n\"\n",
        "        f\"LLM Answer:\\n{generated_text}\"\n",
        "    )\n",
        "\n",
        "def run_query(qobj, top_k_text=TOP_K_TEXT, top_k_images=TOP_K_IMAGES, top_k_evidence=TOP_K_EVIDENCE, alpha=ALPHA) -> Dict[str, Any]:\n",
        "    question = qobj[\"question\"]\n",
        "\n",
        "    # 1. Build Context (Uses your existing function)\n",
        "    ctx = build_context(question, top_k_text=top_k_text, top_k_images=top_k_images, top_k_evidence=top_k_evidence, alpha=alpha)\n",
        "\n",
        "    # 2. Generate Answer\n",
        "    answer = llm_extractive_answer(question, ctx[\"context\"])\n",
        "\n",
        "    # 3. Return exact same structure as your original code\n",
        "    return {\n",
        "        \"id\": qobj[\"query_id\"],\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"context\": ctx[\"context\"],\n",
        "        \"image_paths\": ctx[\"image_paths\"],\n",
        "        \"text_hits\": ctx[\"text_hits\"], # Preserved\n",
        "        \"img_hits\": ctx[\"img_hits\"],   # Preserved\n",
        "    }\n",
        "\n",
        "# --- EXECUTION ---\n",
        "print(\"Running local LLM queries...\")\n",
        "results = [run_query(q) for q in mini_gold]\n",
        "\n",
        "for r in results:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(r[\"id\"], r[\"question\"])\n",
        "    print(r[\"answer\"])\n",
        "    print(\"Images:\", [os.path.basename(p) for p in r[\"image_paths\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDMtnovHTQnY",
        "outputId": "02976551-6423-46e6-cb08-f0f246aa1b81"
      },
      "id": "dDMtnovHTQnY",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running local LLM queries...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Both `max_new_tokens` (=400) and `max_length`(=2048) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "Q1 According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\n",
            "Question: According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\n",
            "\n",
            "LLM Answer:\n",
            "According to doc1.pdf, State Data Breach Notification Laws are prepared by Foley‚Äôs Cybersecurity & Data Privacy Team, and a compliance exception is mentioned regarding good faith acquisition of personal information.\n",
            "Images: ['zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "Q2 What are the main stages shown in the Cyber Kill Chain diagram?\n",
            "Question: What are the main stages shown in the Cyber Kill Chain diagram?\n",
            "\n",
            "LLM Answer:\n",
            "- Harvesting email addresses and conference information\n",
            "- Coupling an exploit with a backdoor into deliverable payload\n",
            "- Exploiting a vulnerability to execute code on victim's system\n",
            "- Installing malware on the asset\n",
            "- Command channel for remote manipulation of the victim\n",
            "- Generating SBOMs and attestations\n",
            "- Evaluating evidence\n",
            "- Having well-established plans, procedures, and roles and responsibilities in place for incident response\n",
            "\n",
            "Reasoning: \n",
            "- The main stages of the Cyber Kill Chain diagram correspond to the main stages in the context of the threat shown in the Question. \n",
            "- The stages in the diagram are shown in the same order as the stages in the context.\n",
            "Images: ['cyber_kill_chain.png']\n",
            "\n",
            "================================================================================\n",
            "Q3 What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?\n",
            "Question: What are the SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram?\n",
            "\n",
            "LLM Answer:\n",
            "The SOC 2 Trust Service Criteria categories shown in the SOC 2 diagram are:\n",
            "\n",
            "1. Identity and Access Management (IDAM)\n",
            "2. Physical Security\n",
            "3. Operational Security\n",
            "4. Business Continuity Planning\n",
            "5. Information Security\n",
            "\n",
            "6. Risk Assessment\n",
            "7. Logical and Physical Access Management\n",
            "8. System Monitoring\n",
            "9. Log and Alerting\n",
            "10. Audit Activities\n",
            "11. Control Activities\n",
            "12. Lp Changes\n",
            "13. System and Organization Controls\n",
            "14. Provectus (Service Organization Controls)\n",
            "15. Zero Trust\n",
            "\n",
            "Note: The SOC 2 report provides detailed descriptions of the Service Organization‚Äôs management approach, controls, and effectiveness in protecting the confidentiality, integrity, and availability of the information in their possession or control.\n",
            "Images: ['soc2_requirements.png', 'zero_trust.png']\n",
            "\n",
            "================================================================================\n",
            "Q4 From the impact-likelihood risk matrix, which area represents the highest risk?\n",
            "Question: From the impact-likelihood risk matrix, which area represents the highest risk?\n",
            "\n",
            "LLM Answer:\n",
            "Impact likelihood matrix identifies the areas where the risk is most significant.\n",
            "\n",
            "Question: Can you provide a brief summary of the findings from the risk management process and its implications for the organization?\n",
            "\n",
            "Answer: The risk management process identifies the areas where the risk is most significant, monitors the risk, and treats the risk.\n",
            "Images: ['risk_management_process.png', 'impact_likelihood_matrix.png']\n",
            "\n",
            "================================================================================\n",
            "Q5 Who won the FIFA World Cup in 2050?\n",
            "Question: Who won the FIFA World Cup in 2050?\n",
            "\n",
            "LLM Answer:\n",
            "France\n",
            "Images: ['cyber_kill_chain.png', 'impact_likelihood_matrix.png', 'network_system_security.png']\n",
            "\n",
            "================================================================================\n",
            "Q6 What are the five core functions shown in the NIST Cybersecurity Framework diagram?\n",
            "Question: What are the five core functions shown in the NIST Cybersecurity Framework diagram?\n",
            "\n",
            "LLM Answer:\n",
            "The five core functions shown in the NIST Cybersecurity Framework diagram are Function, Category, Subcategory, Constraint, and Dashboard.\n",
            "Images: ['nist_framework.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Retrieval Evaluation (Precision@k / Recall@k)**\n",
        "\n",
        "We treat a text chunk as **relevant** for a query if it contains at least one `must_have_keywords` term.\n"
      ],
      "metadata": {
        "id": "FspvAaYRTy3g"
      },
      "id": "FspvAaYRTy3g"
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, Any, List, Set\n",
        "import pandas as pd\n",
        "\n",
        "def _normalize_evidence_id(eid: str) -> str:\n",
        "    \"\"\"Normalize evidence IDs so comparisons work.\n",
        "    Examples:\n",
        "      'img::nist_framework.png' -> 'nist_framework.png'\n",
        "      'doc1.pdf::p3' -> 'doc1.pdf'\n",
        "      'doc1.pdf' -> 'doc1.pdf'\n",
        "    \"\"\"\n",
        "    if not eid:\n",
        "        return \"\"\n",
        "    eid = eid.strip()\n",
        "    if eid.startswith(\"img::\"):\n",
        "        eid = eid.split(\"img::\", 1)[1]\n",
        "    if \"::\" in eid:\n",
        "        eid = eid.split(\"::\", 1)[0]\n",
        "    return eid\n",
        "\n",
        "def _gold_set(qobj: Dict[str, Any]) -> Set[str]:\n",
        "    return set(_normalize_evidence_id(x) for x in qobj.get(\"gold_evidence_ids\", []) if x)\n",
        "\n",
        "def _retrieved_set_from_hits(hits: List[Dict[str, Any]]) -> List[str]:\n",
        "    \"\"\"Given fused evidence dicts from build_context()['evidence'], produce normalized IDs.\"\"\"\n",
        "    out = []\n",
        "    for ev in hits:\n",
        "        if ev.get(\"modality\") == \"text\":\n",
        "            out.append(_normalize_evidence_id(ev.get(\"id\", \"\")))     # e.g., doc1.pdf::p3 -> doc1.pdf\n",
        "        else:\n",
        "            out.append(_normalize_evidence_id(ev.get(\"id\", \"\")))     # e.g., nist_framework.png\n",
        "    return out\n",
        "\n",
        "def precision_at_k(relevances: List[bool], k: int) -> float:\n",
        "    k = min(k, len(relevances))\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    return sum(relevances[:k]) / k\n",
        "\n",
        "def recall_at_k(relevances: List[bool], k: int, total_relevant: int) -> float:\n",
        "    k = min(k, len(relevances))\n",
        "    if total_relevant == 0:\n",
        "        return 0.0\n",
        "    return sum(relevances[:k]) / total_relevant\n",
        "\n",
        "def eval_retrieval_for_query(qobj: Dict[str, Any], top_k_evidence: int = 10) -> Dict[str, Any]:\n",
        "    gold = _gold_set(qobj)\n",
        "    question = qobj[\"question\"]\n",
        "\n",
        "    # Q5-like missing-evidence case: gold is empty -> recall undefined, but we can report 0\n",
        "    # Build multimodal context and use fused evidence list\n",
        "    ctx = build_context(question, top_k_evidence=top_k_evidence)\n",
        "    retrieved_ids = _retrieved_set_from_hits(ctx[\"evidence\"])  # ordered list (ranked)\n",
        "\n",
        "    rels = [rid in gold for rid in retrieved_ids]\n",
        "    total_rel = len(gold)\n",
        "\n",
        "    return {\n",
        "        \"query_id\": qobj.get(\"query_id\", qobj.get(\"id\", \"\")),\n",
        "        \"P@5\": precision_at_k(rels, 5),\n",
        "        \"R@10\": recall_at_k(rels, 10, total_rel),\n",
        "        \"gold_count\": total_rel,\n",
        "        \"retrieved_top\": retrieved_ids[:10],\n",
        "    }\n",
        "\n",
        "eval_rows = [eval_retrieval_for_query(q) for q in mini_gold]\n",
        "df_eval = pd.DataFrame(eval_rows)\n",
        "df_eval\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_Z2jZxWiT6rd",
        "outputId": "6651ee08-7123-439c-857d-1b10bcd34365"
      },
      "id": "_Z2jZxWiT6rd",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  query_id  P@5  R@10  gold_count  \\\n",
              "0       Q1  0.8   5.0           1   \n",
              "1       Q2  0.2   1.0           1   \n",
              "2       Q3  0.2   1.0           1   \n",
              "3       Q4  0.2   1.0           1   \n",
              "4       Q5  0.0   0.0           0   \n",
              "5       Q6  0.2   1.0           1   \n",
              "\n",
              "                                       retrieved_top  \n",
              "0  [doc1.pdf, zero_trust.png, doc1.pdf, doc1.pdf,...  \n",
              "1  [doc4.pdf, doc4.pdf, cyber_kill_chain.png, doc...  \n",
              "2  [doc5.pdf, soc2_requirements.png, zero_trust.p...  \n",
              "3  [doc3.pdf, risk_management_process.png, doc3.p...  \n",
              "4  [doc3.pdf, cyber_kill_chain.png, impact_likeli...  \n",
              "5  [doc3.pdf, doc3.pdf, nist_framework.png, doc3....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7166e9a3-1e92-4d99-b5d2-7d17e37fcbe8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>P@5</th>\n",
              "      <th>R@10</th>\n",
              "      <th>gold_count</th>\n",
              "      <th>retrieved_top</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[doc1.pdf, zero_trust.png, doc1.pdf, doc1.pdf,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[doc4.pdf, doc4.pdf, cyber_kill_chain.png, doc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[doc5.pdf, soc2_requirements.png, zero_trust.p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[doc3.pdf, risk_management_process.png, doc3.p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>[doc3.pdf, cyber_kill_chain.png, impact_likeli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q6</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>[doc3.pdf, doc3.pdf, nist_framework.png, doc3....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7166e9a3-1e92-4d99-b5d2-7d17e37fcbe8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7166e9a3-1e92-4d99-b5d2-7d17e37fcbe8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7166e9a3-1e92-4d99-b5d2-7d17e37fcbe8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_0b962ba3-5001-4780-a190-2232f043e107\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0b962ba3-5001-4780-a190-2232f043e107 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_eval",
              "summary": "{\n  \"name\": \"df_eval\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"query_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"P@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2732520204255893,\n        \"min\": 0.0,\n        \"max\": 0.8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.8,\n          0.2,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R@10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.760681686165901,\n        \"min\": 0.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          5.0,\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_top\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "METHODS = [\"Sparse Only\", \"Dense Only\", \"Hybrid\", \"Hybrid + Rerank\", \"Multimodal\"]\n",
        "eval_results = []\n",
        "\n",
        "def normalize_evidence_id(eid: str) -> str:\n",
        "    \"\"\"Make evidence IDs comparable between gold and retrieved.\"\"\"\n",
        "    if not eid:\n",
        "        return \"\"\n",
        "    eid = eid.strip()\n",
        "    if eid.startswith(\"img::\"):\n",
        "        eid = eid.split(\"img::\", 1)[1]\n",
        "    # If chunk ids look like \"doc1.pdf::p3\", normalize to \"doc1.pdf\"\n",
        "    if \"::\" in eid:\n",
        "        eid = eid.split(\"::\", 1)[0]\n",
        "    return eid\n",
        "\n",
        "def gold_set_for_query(qobj):\n",
        "    return set(normalize_evidence_id(x) for x in qobj.get(\"gold_evidence_ids\", []) if x)\n",
        "\n",
        "def precision_at_k_bool(rels, k):\n",
        "    k = min(k, len(rels))\n",
        "    if k == 0:\n",
        "        return 0.0\n",
        "    return sum(rels[:k]) / k\n",
        "\n",
        "def recall_at_k_bool(rels, k, total_rel):\n",
        "    k = min(k, len(rels))\n",
        "    if total_rel == 0:\n",
        "        return 0.0\n",
        "    return sum(rels[:k]) / total_rel\n",
        "\n",
        "print(\"Running evaluation across all methods...\")\n",
        "\n",
        "for qobj in mini_gold:\n",
        "    qid = qobj[\"query_id\"]\n",
        "    question = qobj[\"question\"]\n",
        "    gold = gold_set_for_query(qobj)\n",
        "    total_relevant = len(gold)   # ground-truth count for this query\n",
        "\n",
        "    for method in METHODS:\n",
        "        retrieved_ids = []\n",
        "\n",
        "        if method == \"Multimodal\":\n",
        "            # Text part: use your best text method as candidates\n",
        "            text_hits = get_retrieval_results(question, \"Hybrid + Rerank\", top_k=10)\n",
        "            for idx, _ in text_hits:\n",
        "                # normalize chunk_id -> doc filename\n",
        "                retrieved_ids.append(normalize_evidence_id(page_chunks[idx].chunk_id))\n",
        "\n",
        "            # Image part\n",
        "            img_hits = tfidf_retrieve(question, img_vec, img_X, top_k=5)\n",
        "            for idx, _ in img_hits:\n",
        "                # image id should be the filename\n",
        "                retrieved_ids.append(normalize_evidence_id(image_items[idx].item_id))\n",
        "\n",
        "        else:\n",
        "            hits = get_retrieval_results(question, method, top_k=10)\n",
        "            for idx, _ in hits:\n",
        "                retrieved_ids.append(normalize_evidence_id(page_chunks[idx].chunk_id))\n",
        "\n",
        "        # Convert to relevance booleans against gold evidence ids (ranked list)\n",
        "        rels = [(rid in gold) for rid in retrieved_ids]\n",
        "\n",
        "        p5 = precision_at_k_bool(rels, 5)\n",
        "        r10 = recall_at_k_bool(rels, 10, total_relevant)\n",
        "\n",
        "        eval_results.append({\n",
        "            \"Query\": qid,\n",
        "            \"Method\": method,\n",
        "            \"Precision@5\": round(p5, 2),\n",
        "            \"Recall@10\": round(r10, 2),\n",
        "            \"Gold_Evidence_Count\": total_relevant,\n",
        "            \"Gold_Evidence\": sorted(list(gold)),\n",
        "            \"Retrieved_Top\": retrieved_ids[:10],\n",
        "        })\n",
        "\n",
        "df_results = pd.DataFrame(eval_results)\n",
        "\n",
        "print(\"\\n=== Final Deliverable Table (Query x Method x Metrics) ===\")\n",
        "display(df_results[[\"Query\",\"Method\",\"Precision@5\",\"Recall@10\",\"Gold_Evidence_Count\"]])\n",
        "\n",
        "print(\"\\n=== Comparison View (Precision@5) ===\")\n",
        "display(df_results.pivot(index=\"Query\", columns=\"Method\", values=\"Precision@5\"))\n",
        "\n",
        "print(\"\\n=== Comparison View (Recall@10) ===\")\n",
        "display(df_results.pivot(index=\"Query\", columns=\"Method\", values=\"Recall@10\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fdDXxmK4VVDF",
        "outputId": "ea331c52-8fed-4d05-c49d-4d3827b26ad9"
      },
      "id": "fdDXxmK4VVDF",
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running evaluation across all methods...\n",
            "\n",
            "=== Final Deliverable Table (Query x Method x Metrics) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Query           Method  Precision@5  Recall@10  Gold_Evidence_Count\n",
              "0     Q1      Sparse Only          1.0        9.0                    1\n",
              "1     Q1       Dense Only          1.0       10.0                    1\n",
              "2     Q1           Hybrid          1.0       10.0                    1\n",
              "3     Q1  Hybrid + Rerank          1.0       10.0                    1\n",
              "4     Q1       Multimodal          1.0       10.0                    1\n",
              "5     Q2      Sparse Only          0.0        0.0                    1\n",
              "6     Q2       Dense Only          0.0        0.0                    1\n",
              "7     Q2           Hybrid          0.0        0.0                    1\n",
              "8     Q2  Hybrid + Rerank          0.0        0.0                    1\n",
              "9     Q2       Multimodal          0.0        0.0                    1\n",
              "10    Q3      Sparse Only          0.0        0.0                    1\n",
              "11    Q3       Dense Only          0.0        0.0                    1\n",
              "12    Q3           Hybrid          0.0        0.0                    1\n",
              "13    Q3  Hybrid + Rerank          0.0        0.0                    1\n",
              "14    Q3       Multimodal          0.0        0.0                    1\n",
              "15    Q4      Sparse Only          0.0        0.0                    1\n",
              "16    Q4       Dense Only          0.0        0.0                    1\n",
              "17    Q4           Hybrid          0.0        0.0                    1\n",
              "18    Q4  Hybrid + Rerank          0.0        0.0                    1\n",
              "19    Q4       Multimodal          0.0        0.0                    1\n",
              "20    Q5      Sparse Only          0.0        0.0                    0\n",
              "21    Q5       Dense Only          0.0        0.0                    0\n",
              "22    Q5           Hybrid          0.0        0.0                    0\n",
              "23    Q5  Hybrid + Rerank          0.0        0.0                    0\n",
              "24    Q5       Multimodal          0.0        0.0                    0\n",
              "25    Q6      Sparse Only          0.0        0.0                    1\n",
              "26    Q6       Dense Only          0.0        0.0                    1\n",
              "27    Q6           Hybrid          0.0        0.0                    1\n",
              "28    Q6  Hybrid + Rerank          0.0        0.0                    1\n",
              "29    Q6       Multimodal          0.0        0.0                    1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c4f4cbd-c47d-4513-a286-205b8f793e4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Query</th>\n",
              "      <th>Method</th>\n",
              "      <th>Precision@5</th>\n",
              "      <th>Recall@10</th>\n",
              "      <th>Gold_Evidence_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q1</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q1</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q1</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q1</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>1.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Q2</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Q3</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Q4</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Q6</td>\n",
              "      <td>Sparse Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Q6</td>\n",
              "      <td>Dense Only</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Q6</td>\n",
              "      <td>Hybrid</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Q6</td>\n",
              "      <td>Hybrid + Rerank</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Q6</td>\n",
              "      <td>Multimodal</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c4f4cbd-c47d-4513-a286-205b8f793e4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c4f4cbd-c47d-4513-a286-205b8f793e4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c4f4cbd-c47d-4513-a286-205b8f793e4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_results\",\n  \"rows\": 30,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Method\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Dense Only\",\n          \"Multimodal\",\n          \"Hybrid\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision@5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3790490217894516,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall@10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.7183916928706124,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          9.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Gold_Evidence_Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparison View (Precision@5) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Method  Dense Only  Hybrid  Hybrid + Rerank  Multimodal  Sparse Only\n",
              "Query                                                               \n",
              "Q1             1.0     1.0              1.0         1.0          1.0\n",
              "Q2             0.0     0.0              0.0         0.0          0.0\n",
              "Q3             0.0     0.0              0.0         0.0          0.0\n",
              "Q4             0.0     0.0              0.0         0.0          0.0\n",
              "Q5             0.0     0.0              0.0         0.0          0.0\n",
              "Q6             0.0     0.0              0.0         0.0          0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f71dd624-7e21-4a06-9eb5-698fcf6ed578\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Method</th>\n",
              "      <th>Dense Only</th>\n",
              "      <th>Hybrid</th>\n",
              "      <th>Hybrid + Rerank</th>\n",
              "      <th>Multimodal</th>\n",
              "      <th>Sparse Only</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Query</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f71dd624-7e21-4a06-9eb5-698fcf6ed578')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f71dd624-7e21-4a06-9eb5-698fcf6ed578 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f71dd624-7e21-4a06-9eb5-698fcf6ed578');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dense Only\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hybrid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hybrid + Rerank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multimodal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sparse Only\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.408248290463863,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Comparison View (Recall@10) ===\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Method  Dense Only  Hybrid  Hybrid + Rerank  Multimodal  Sparse Only\n",
              "Query                                                               \n",
              "Q1            10.0    10.0             10.0        10.0          9.0\n",
              "Q2             0.0     0.0              0.0         0.0          0.0\n",
              "Q3             0.0     0.0              0.0         0.0          0.0\n",
              "Q4             0.0     0.0              0.0         0.0          0.0\n",
              "Q5             0.0     0.0              0.0         0.0          0.0\n",
              "Q6             0.0     0.0              0.0         0.0          0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ea60c443-b0b1-4331-89ec-cec085efa65c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Method</th>\n",
              "      <th>Dense Only</th>\n",
              "      <th>Hybrid</th>\n",
              "      <th>Hybrid + Rerank</th>\n",
              "      <th>Multimodal</th>\n",
              "      <th>Sparse Only</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Query</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Q1</th>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q5</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q6</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea60c443-b0b1-4331-89ec-cec085efa65c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ea60c443-b0b1-4331-89ec-cec085efa65c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ea60c443-b0b1-4331-89ec-cec085efa65c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_results\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Query\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dense Only\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0824829046386295,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hybrid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0824829046386295,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hybrid + Rerank\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0824829046386295,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Multimodal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.0824829046386295,\n        \"min\": 0.0,\n        \"max\": 10.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sparse Only\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.6742346141747673,\n        \"min\": 0.0,\n        \"max\": 9.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          9.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7629d00",
      "metadata": {
        "id": "d7629d00"
      },
      "source": [
        "# 6) Evaluation + Logging (Required)\n",
        "\n",
        "Every query must append to: `logs/query_metrics.csv`\n",
        "\n",
        "Required columns (minimum):\n",
        "- timestamp\n",
        "- query_id\n",
        "- retrieval_mode\n",
        "- top_k\n",
        "- latency_ms\n",
        "- Precision@5\n",
        "- Recall@10\n",
        "- evidence_ids_returned\n",
        "- faithfulness_pass\n",
        "- missing_evidence_behavior\n",
        "\n",
        "> If your gold set is incomplete (common for Q4/Q5), compute P/R only for labeled queries and still log latency/evidence IDs.\n",
        "\n",
        "## How we define metrics (simple)\n",
        "- `Precision@K`: (# retrieved evidence IDs in gold) / K\n",
        "- `Recall@K`: (# retrieved evidence IDs in gold) / (size of gold set)\n",
        "\n",
        "**Faithfulness (Yes/No):**\n",
        "- Yes if the answer **only** uses retrieved evidence and includes citations.\n",
        "- For this template, we implement a simple heuristic. Replace with your rubric/judge if desired.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "850487f0",
      "metadata": {
        "id": "850487f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "88afaef3-b2f0-425d-da18-fe13e21e7cc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           timestamp query_id retrieval_mode  top_k  \\\n",
              "10  2026-02-12T16:50:25.308178+00:00       Q5         hybrid     10   \n",
              "11  2026-02-12T16:50:25.310519+00:00       Q6         hybrid     10   \n",
              "12  2026-02-12T17:19:12.112058+00:00       Q1         hybrid     10   \n",
              "13  2026-02-12T17:19:12.113916+00:00       Q2         hybrid     10   \n",
              "14  2026-02-12T17:19:12.115594+00:00       Q3         hybrid     10   \n",
              "15  2026-02-12T17:19:12.117229+00:00       Q4         hybrid     10   \n",
              "16  2026-02-12T17:19:12.118662+00:00       Q5         hybrid     10   \n",
              "17  2026-02-12T17:19:12.120164+00:00       Q6         hybrid     10   \n",
              "\n",
              "    latency_ms  Precision@5  Recall@10  \\\n",
              "10        2.21          NaN        NaN   \n",
              "11        2.10          0.0        0.0   \n",
              "12        2.58          0.0        0.0   \n",
              "13        1.58          0.0        0.0   \n",
              "14        1.51          0.0        0.0   \n",
              "15        1.42          0.0        0.0   \n",
              "16        1.31          NaN        NaN   \n",
              "17        1.35          0.0        0.0   \n",
              "\n",
              "                       evidence_ids_returned  \\\n",
              "10  [\"doc4\", \"doc3\", \"doc2\", \"doc1\", \"doc5\"]   \n",
              "11  [\"doc3\", \"doc2\", \"doc4\", \"doc5\", \"doc1\"]   \n",
              "12  [\"doc1\", \"doc2\", \"doc4\", \"doc5\", \"doc3\"]   \n",
              "13  [\"doc2\", \"doc4\", \"doc3\", \"doc1\", \"doc5\"]   \n",
              "14  [\"doc5\", \"doc4\", \"doc3\", \"doc2\", \"doc1\"]   \n",
              "15  [\"doc3\", \"doc4\", \"doc5\", \"doc1\", \"doc2\"]   \n",
              "16  [\"doc4\", \"doc3\", \"doc2\", \"doc1\", \"doc5\"]   \n",
              "17  [\"doc3\", \"doc2\", \"doc4\", \"doc5\", \"doc1\"]   \n",
              "\n",
              "                        gold_evidence_ids faithfulness_pass  \\\n",
              "10                                     []               Yes   \n",
              "11            [\"img::nist_framework.png\"]               Yes   \n",
              "12                           [\"doc1.pdf\"]               Yes   \n",
              "13          [\"img::cyber_kill_chain.png\"]               Yes   \n",
              "14         [\"img::soc2_requirements.png\"]               Yes   \n",
              "15  [\"img::impact_likelihood_matrix.png\"]               Yes   \n",
              "16                                     []               Yes   \n",
              "17            [\"img::nist_framework.png\"]               Yes   \n",
              "\n",
              "   missing_evidence_behavior  \n",
              "10                      Pass  \n",
              "11                      Pass  \n",
              "12                      Pass  \n",
              "13                      Pass  \n",
              "14                      Pass  \n",
              "15                      Pass  \n",
              "16                      Pass  \n",
              "17                      Pass  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ffc61965-3dde-4491-965c-988d50da3c4b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timestamp</th>\n",
              "      <th>query_id</th>\n",
              "      <th>retrieval_mode</th>\n",
              "      <th>top_k</th>\n",
              "      <th>latency_ms</th>\n",
              "      <th>Precision@5</th>\n",
              "      <th>Recall@10</th>\n",
              "      <th>evidence_ids_returned</th>\n",
              "      <th>gold_evidence_ids</th>\n",
              "      <th>faithfulness_pass</th>\n",
              "      <th>missing_evidence_behavior</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2026-02-12T16:50:25.308178+00:00</td>\n",
              "      <td>Q5</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>2.21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"doc4\", \"doc3\", \"doc2\", \"doc1\", \"doc5\"]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2026-02-12T16:50:25.310519+00:00</td>\n",
              "      <td>Q6</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>2.10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc3\", \"doc2\", \"doc4\", \"doc5\", \"doc1\"]</td>\n",
              "      <td>[\"img::nist_framework.png\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2026-02-12T17:19:12.112058+00:00</td>\n",
              "      <td>Q1</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>2.58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc1\", \"doc2\", \"doc4\", \"doc5\", \"doc3\"]</td>\n",
              "      <td>[\"doc1.pdf\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2026-02-12T17:19:12.113916+00:00</td>\n",
              "      <td>Q2</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc2\", \"doc4\", \"doc3\", \"doc1\", \"doc5\"]</td>\n",
              "      <td>[\"img::cyber_kill_chain.png\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2026-02-12T17:19:12.115594+00:00</td>\n",
              "      <td>Q3</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>1.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc5\", \"doc4\", \"doc3\", \"doc2\", \"doc1\"]</td>\n",
              "      <td>[\"img::soc2_requirements.png\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2026-02-12T17:19:12.117229+00:00</td>\n",
              "      <td>Q4</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>1.42</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc3\", \"doc4\", \"doc5\", \"doc1\", \"doc2\"]</td>\n",
              "      <td>[\"img::impact_likelihood_matrix.png\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2026-02-12T17:19:12.118662+00:00</td>\n",
              "      <td>Q5</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>1.31</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"doc4\", \"doc3\", \"doc2\", \"doc1\", \"doc5\"]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2026-02-12T17:19:12.120164+00:00</td>\n",
              "      <td>Q6</td>\n",
              "      <td>hybrid</td>\n",
              "      <td>10</td>\n",
              "      <td>1.35</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>[\"doc3\", \"doc2\", \"doc4\", \"doc5\", \"doc1\"]</td>\n",
              "      <td>[\"img::nist_framework.png\"]</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Pass</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ffc61965-3dde-4491-965c-988d50da3c4b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ffc61965-3dde-4491-965c-988d50da3c4b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ffc61965-3dde-4491-965c-988d50da3c4b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ],
      "source": [
        "import os\n",
        "import csv\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "\n",
        "\n",
        "def _canon_evidence_id(x: str) -> str:\n",
        "    x = str(x).strip()\n",
        "    # keep img:: prefix intact\n",
        "    if x.startswith('img::'):\n",
        "        return x\n",
        "    # normalize file ids: allow with/without extension\n",
        "    if x.endswith('.txt'):\n",
        "        return x[:-4]\n",
        "    return x\n",
        "\n",
        "def _normalize_retrieved_ids(retrieved):\n",
        "    \"\"\"Normalize retrieved outputs into a list of evidence IDs.\n",
        "    Returns canonical IDs (doc_id without .txt, or img::filename).\n",
        "\n",
        "    Supports: list[dict], list[(idx,score)], list[str].\n",
        "    \"\"\"\n",
        "    if retrieved is None:\n",
        "        return []\n",
        "    if len(retrieved) == 0:\n",
        "        return []\n",
        "    # list[str]\n",
        "    if isinstance(retrieved[0], str):\n",
        "        return [_canon_evidence_id(r) for r in retrieved]\n",
        "    # list[dict]\n",
        "    if isinstance(retrieved[0], dict):\n",
        "        out=[]\n",
        "        for r in retrieved:\n",
        "            if 'evidence_id' in r and r['evidence_id']:\n",
        "                out.append(_canon_evidence_id(r['evidence_id']))\n",
        "            elif 'doc_id' in r and r['doc_id']:\n",
        "                out.append(_canon_evidence_id(r['doc_id']))\n",
        "            elif 'source' in r and r['source']:\n",
        "                out.append(_canon_evidence_id(os.path.basename(str(r['source']))))\n",
        "        return out\n",
        "    # list[(idx, score)]\n",
        "    if isinstance(retrieved[0], (tuple, list)) and len(retrieved[0]) >= 1:\n",
        "        out=[]\n",
        "        for item in retrieved:\n",
        "            idx = int(item[0])\n",
        "            if 'items' in globals() and 0 <= idx < len(items):\n",
        "                out.append(_canon_evidence_id(items[idx].get('evidence_id')))\n",
        "            elif 'documents' in globals() and 0 <= idx < len(documents):\n",
        "                out.append(_canon_evidence_id(documents[idx].get('doc_id') or os.path.basename(documents[idx].get('source',''))))\n",
        "        return out\n",
        "    return []\n",
        "\n",
        "def _normalize_gold_ids(gold_ids):\n",
        "    if not gold_ids or gold_ids == ['N/A']:\n",
        "        return None\n",
        "    return [_canon_evidence_id(g) for g in gold_ids]\n",
        "\n",
        "def precision_at_k(retrieved, gold_ids, k):\n",
        "    gold = _normalize_gold_ids(gold_ids)\n",
        "    if gold is None:\n",
        "        return None\n",
        "    retrieved_ids = _normalize_retrieved_ids(retrieved)[:k]\n",
        "    if k == 0:\n",
        "        return None\n",
        "    return len(set(retrieved_ids) & set(gold)) / float(k)\n",
        "\n",
        "def recall_at_k(retrieved, gold_ids, k):\n",
        "    gold = _normalize_gold_ids(gold_ids)\n",
        "    if gold is None:\n",
        "        return None\n",
        "    retrieved_ids = _normalize_retrieved_ids(retrieved)[:k]\n",
        "    denom = float(len(set(gold)))\n",
        "    return (len(set(retrieved_ids) & set(gold)) / denom) if denom > 0 else None\n",
        "\n",
        "\n",
        "\n",
        "def faithfulness_heuristic(answer: str, evidence: list):\n",
        "    # Simple heuristic: answer includes at least one citation tag from evidence OR is missing-evidence msg\n",
        "    if answer.strip() == MISSING_EVIDENCE_MSG:\n",
        "        return True\n",
        "    tags = [e[\"citation_tag\"] for e in evidence[:5]]\n",
        "    return any(tag in answer for tag in tags)\n",
        "\n",
        "def missing_evidence_behavior(answer: str, evidence: list):\n",
        "    # Pass if either: evidence present and answer not missing-evidence; or evidence absent and answer is missing-evidence msg\n",
        "    has_ev = bool(evidence) and max(e.get(\"score\", 0.0) for e in evidence) >= 0.05\n",
        "    if not has_ev:\n",
        "        return \"Pass\" if answer.strip() == MISSING_EVIDENCE_MSG else \"Fail\"\n",
        "    else:\n",
        "        return \"Pass\" if answer.strip() != MISSING_EVIDENCE_MSG else \"Fail\"\n",
        "\n",
        "def ensure_logfile(path: str, header: list):\n",
        "    p = Path(path)\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not p.exists():\n",
        "        with open(p, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(header)\n",
        "\n",
        "LOG_HEADER = [\n",
        "    \"timestamp\", \"query_id\", \"retrieval_mode\", \"top_k\", \"latency_ms\",\n",
        "    \"Precision@5\", \"Recall@10\",\n",
        "    \"evidence_ids_returned\", \"gold_evidence_ids\",\n",
        "    \"faithfulness_pass\", \"missing_evidence_behavior\"\n",
        "]\n",
        "ensure_logfile(cfg.log_file, LOG_HEADER)\n",
        "\n",
        "def run_query_and_log(query_item, retrieval_mode = 'hybrid', top_k=10):\n",
        "    question = query_item[\"question\"]\n",
        "    gold_ids = query_item.get(\"gold_evidence_ids\", [])\n",
        "\n",
        "    t0 = time.time()\n",
        "    evidence = retrieve_tfidf(question, top_k=top_k)  # replace with your pipeline + modes\n",
        "    answer = generate_answer_stub(question, evidence) # replace with LLM/VLM\n",
        "    latency_ms = (time.time() - t0) * 1000.0\n",
        "\n",
        "    retrieved_ids = [e[\"chunk_id\"] for e in evidence]\n",
        "    p5 = precision_at_k(retrieved_ids, gold_ids, cfg.eval_p_at) if gold_ids else np.nan\n",
        "    r10 = recall_at_k(retrieved_ids, gold_ids, cfg.eval_r_at) if gold_ids else np.nan\n",
        "\n",
        "    faithful = faithfulness_heuristic(answer, evidence)\n",
        "    meb = missing_evidence_behavior(answer, evidence)\n",
        "\n",
        "    row = [\n",
        "        datetime.now(timezone.utc).isoformat(),\n",
        "        query_item[\"query_id\"],\n",
        "        retrieval_mode,\n",
        "        top_k,\n",
        "        round(latency_ms, 2),\n",
        "        p5,\n",
        "        r10,\n",
        "        json.dumps(retrieved_ids),\n",
        "        json.dumps(gold_ids),\n",
        "        \"Yes\" if faithful else \"No\",\n",
        "        meb\n",
        "    ]\n",
        "    with open(cfg.log_file, \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(row)\n",
        "\n",
        "    return {\"answer\": answer, \"evidence\": evidence, \"p5\": p5, \"r10\": r10, \"latency_ms\": latency_ms, \"faithful\": faithful, \"meb\": meb}\n",
        "\n",
        "# Run all five queries once (demo)\n",
        "results = []\n",
        "for qi in mini_gold:\n",
        "    results.append(run_query_and_log(qi, retrieval_mode = 'hybrid', top_k=cfg.top_k_default))\n",
        "\n",
        "pd.read_csv(cfg.log_file).tail(8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "ungUxBVhbK44",
      "metadata": {
        "id": "ungUxBVhbK44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "28d6c8d3-85a1-4c95-a09a-fb712520e0f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  query_id                                           question  \\\n",
              "0       Q1  According to doc1.pdf, what are State Data Bre...   \n",
              "1       Q2  What are the main stages shown in the Cyber Ki...   \n",
              "2       Q3  What are the SOC 2 Trust Service Criteria cate...   \n",
              "3       Q4  From the impact-likelihood risk matrix, which ...   \n",
              "4       Q5                Who won the FIFA World Cup in 2050?   \n",
              "5       Q6  What are the five core functions shown in the ...   \n",
              "\n",
              "                                              answer  \\\n",
              "0  Based on the retrieved evidence [doc1], the sy...   \n",
              "1  Based on the retrieved evidence [doc2], the sy...   \n",
              "2  Based on the retrieved evidence [doc5], the sy...   \n",
              "3  Based on the retrieved evidence [doc3], the sy...   \n",
              "4      Not enough evidence in the retrieved context.   \n",
              "5  Based on the retrieved evidence [doc3], the sy...   \n",
              "\n",
              "     evidence_ids_returned(top10)                    gold_evidence_ids  \n",
              "0  [doc1, doc2, doc4, doc5, doc3]                           [doc1.pdf]  \n",
              "1  [doc2, doc4, doc3, doc1, doc5]          [img::cyber_kill_chain.png]  \n",
              "2  [doc5, doc4, doc3, doc2, doc1]         [img::soc2_requirements.png]  \n",
              "3  [doc3, doc4, doc5, doc1, doc2]  [img::impact_likelihood_matrix.png]  \n",
              "4  [doc4, doc3, doc2, doc1, doc5]                                   []  \n",
              "5  [doc3, doc2, doc4, doc5, doc1]            [img::nist_framework.png]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9b40bad-e02f-48d2-af3d-86cce96076e3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query_id</th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>evidence_ids_returned(top10)</th>\n",
              "      <th>gold_evidence_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>According to doc1.pdf, what are State Data Bre...</td>\n",
              "      <td>Based on the retrieved evidence [doc1], the sy...</td>\n",
              "      <td>[doc1, doc2, doc4, doc5, doc3]</td>\n",
              "      <td>[doc1.pdf]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q2</td>\n",
              "      <td>What are the main stages shown in the Cyber Ki...</td>\n",
              "      <td>Based on the retrieved evidence [doc2], the sy...</td>\n",
              "      <td>[doc2, doc4, doc3, doc1, doc5]</td>\n",
              "      <td>[img::cyber_kill_chain.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q3</td>\n",
              "      <td>What are the SOC 2 Trust Service Criteria cate...</td>\n",
              "      <td>Based on the retrieved evidence [doc5], the sy...</td>\n",
              "      <td>[doc5, doc4, doc3, doc2, doc1]</td>\n",
              "      <td>[img::soc2_requirements.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q4</td>\n",
              "      <td>From the impact-likelihood risk matrix, which ...</td>\n",
              "      <td>Based on the retrieved evidence [doc3], the sy...</td>\n",
              "      <td>[doc3, doc4, doc5, doc1, doc2]</td>\n",
              "      <td>[img::impact_likelihood_matrix.png]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5</td>\n",
              "      <td>Who won the FIFA World Cup in 2050?</td>\n",
              "      <td>Not enough evidence in the retrieved context.</td>\n",
              "      <td>[doc4, doc3, doc2, doc1, doc5]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Q6</td>\n",
              "      <td>What are the five core functions shown in the ...</td>\n",
              "      <td>Based on the retrieved evidence [doc3], the sy...</td>\n",
              "      <td>[doc3, doc2, doc4, doc5, doc1]</td>\n",
              "      <td>[img::nist_framework.png]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9b40bad-e02f-48d2-af3d-86cce96076e3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e9b40bad-e02f-48d2-af3d-86cce96076e3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e9b40bad-e02f-48d2-af3d-86cce96076e3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_ff3d8dc5-0305-430b-bba2-924b5a6b6528\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_answers')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ff3d8dc5-0305-430b-bba2-924b5a6b6528 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_answers');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_answers",
              "summary": "{\n  \"name\": \"df_answers\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"query_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Q1\",\n          \"Q2\",\n          \"Q6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"According to doc1.pdf, what are State Data Breach Notification Laws and what compliance exception is mentioned?\",\n          \"What are the main stages shown in the Cyber Kill Chain diagram?\",\n          \"What are the five core functions shown in the NIST Cybersecurity Framework diagram?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Based on the retrieved evidence [doc2], the system should ground its response in retrieved context and cite sources. If evidence is missing, it must respond with: 'Not enough evidence in the retrieved context.'. [doc2]\",\n          \"Not enough evidence in the retrieved context.\",\n          \"Based on the retrieved evidence [doc5], the system should ground its response in retrieved context and cite sources. If evidence is missing, it must respond with: 'Not enough evidence in the retrieved context.'. [doc5]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"evidence_ids_returned(top10)\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gold_evidence_ids\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# Task: Run retrieval + answer generation for all mini-gold queries\n",
        "# This cell is self-contained: if retrieval/indexing cells were skipped, it will bootstrap a TF-IDF retriever.\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Build a local evidence list if not already present\n",
        "if 'items' in globals():\n",
        "    _evidence = items\n",
        "elif 'documents' in globals():\n",
        "    _evidence = []\n",
        "    for d in documents:\n",
        "        _evidence.append({\n",
        "            'evidence_id': d.get('doc_id') or os.path.basename(d.get('source','')),\n",
        "            'modality': 'text',\n",
        "            'source': d.get('source'),\n",
        "            'text': d.get('text','')\n",
        "        })\n",
        "else:\n",
        "    raise NameError('Neither items nor documents are defined. Run the ZIP extraction + document loading cells first.')\n",
        "\n",
        "assert len(_evidence) > 0, 'Evidence store is empty.'\n",
        "\n",
        "# Canonicalize evidence ids for consistent evaluation\n",
        "def _canon_evidence_id(x: str) -> str:\n",
        "    x = str(x).strip()\n",
        "    if x.startswith('img::'):\n",
        "        return x\n",
        "    return x[:-4] if x.endswith('.txt') else x\n",
        "\n",
        "# Bootstrap TF-IDF retriever if no retriever exists\n",
        "if 'retrieve_hybrid' not in globals() and 'retrieve_tfidf' not in globals() and 'retrieve' not in globals():\n",
        "    _texts = [it.get('text','') for it in _evidence]\n",
        "    _tfidf = TfidfVectorizer(stop_words=None, token_pattern=r'(?u)\\b\\w+\\b')\n",
        "    _tfidf_mat = _tfidf.fit_transform(_texts)\n",
        "\n",
        "    def retrieve_tfidf(query, top_k=10):\n",
        "        qv = _tfidf.transform([query])\n",
        "        sims = cosine_similarity(qv, _tfidf_mat).ravel()\n",
        "        idx = np.argsort(sims)[::-1][:top_k]\n",
        "        return [(int(i), float(sims[i])) for i in idx]\n",
        "\n",
        "# Define retrieve() wrapper if missing\n",
        "if 'retrieve' not in globals():\n",
        "    def retrieve(question, retrieval_mode='hybrid', top_k=10, alpha=0.6):\n",
        "        # Prefer hybrid if available; otherwise TF-IDF\n",
        "        if retrieval_mode == 'hybrid' and 'retrieve_hybrid' in globals():\n",
        "            hits = retrieve_hybrid(question, top_k=top_k, alpha=alpha)\n",
        "            return hits, {'mode':'hybrid'}\n",
        "        if 'retrieve_tfidf' in globals():\n",
        "            hits = retrieve_tfidf(question, top_k=top_k)\n",
        "            return hits, {'mode':'tfidf'}\n",
        "        raise NameError('No retriever available. Execute the retrieval/indexing section.')\n",
        "\n",
        "# Ensure build_context exists\n",
        "if 'build_context' not in globals():\n",
        "    def build_context(hit_ids, max_chars=1400):\n",
        "        parts=[]\n",
        "        for i in hit_ids:\n",
        "            parts.append(f\"[{_evidence[i].get('evidence_id')}] {_evidence[i].get('text','')}\")\n",
        "        ctx='\\n'.join(parts)\n",
        "        return ctx[:max_chars]\n",
        "\n",
        "# Ensure extractive_answer exists\n",
        "if 'extractive_answer' not in globals():\n",
        "    import re\n",
        "    def extractive_answer(query, context):\n",
        "        q=set(re.findall(r'[A-Za-z]+', query.lower()))\n",
        "        sents=re.split(r'(?<=[.!?])\\s+', (context or '').strip())\n",
        "        scored=[]\n",
        "        for s in sents:\n",
        "            w=set(re.findall(r'[A-Za-z]+', s.lower()))\n",
        "            scored.append((len(q & w), s.strip()))\n",
        "        scored.sort(key=lambda x:x[0], reverse=True)\n",
        "        best=[s for sc,s in scored[:3] if sc>0]\n",
        "        return ' '.join(best) if best else 'Not enough information in the context.'\n",
        "\n",
        "rows=[]\n",
        "for ex in mini_gold:\n",
        "    qid = ex.get('query_id')\n",
        "    question = ex.get('question')\n",
        "    gold = ex.get('gold_evidence_ids')\n",
        "\n",
        "    if 'run_query_and_log' in globals():\n",
        "        # Call run_query_and_log with the full query item dictionary 'ex'\n",
        "        out = run_query_and_log(ex, retrieval_mode='hybrid', top_k=10)\n",
        "        answer = out.get('answer')\n",
        "        # The 'evidence' key from run_query_and_log output contains a list of dicts with 'chunk_id'\n",
        "        evidence = [e['chunk_id'] for e in out.get('evidence', [])]\n",
        "    else:\n",
        "        hits, debug = retrieve(question, retrieval_mode='hybrid', top_k=10)\n",
        "        hit_ids = [int(i) for i,_ in hits]\n",
        "        context = build_context(hit_ids[:10])\n",
        "        answer = extractive_answer(question, context)\n",
        "        evidence = [_canon_evidence_id(_evidence[i].get('evidence_id')) for i in hit_ids[:10]]\n",
        "\n",
        "    rows.append({\n",
        "        'query_id': qid,\n",
        "        'question': question,\n",
        "        'answer': answer,\n",
        "        'evidence_ids_returned(top10)': evidence,\n",
        "        'gold_evidence_ids': gold,\n",
        "    })\n",
        "\n",
        "df_answers = pd.DataFrame(rows)\n",
        "df_answers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46e71b22",
      "metadata": {
        "id": "46e71b22"
      },
      "source": [
        "# 7) Streamlit App Skeleton (Required)\n",
        "\n",
        "You will create a Streamlit app file in your repo, e.g.:\n",
        "\n",
        "- `app/main.py`\n",
        "\n",
        "This notebook can generate a starter `app/main.py` for your team.\n",
        "\n",
        "### Required UI components\n",
        "- Query input box\n",
        "- Retrieval controls (mode, top_k, multimodal toggle if applicable)\n",
        "- Answer panel\n",
        "- Evidence panel (with citations)\n",
        "- Metrics panel (latency, P@5, R@10 if available)\n",
        "- Logging happens automatically on each query\n",
        "\n",
        "> This skeleton calls functions in your Python modules. Prefer moving retrieval logic into `/rag/` and importing it.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n"
      ],
      "metadata": {
        "id": "JFzXkEthOxrq"
      },
      "id": "JFzXkEthOxrq",
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "bb966c49",
      "metadata": {
        "id": "bb966c49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa49135-4670-4b25-9bbd-88f5fca5a2db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote starter Streamlit app to: app/main.py\n"
          ]
        }
      ],
      "source": [
        "# Generate a starter Streamlit app file (edit paths as needed).\n",
        "# In your repo: create /app/main.py and move shared logic into /rag/\n",
        "\n",
        "streamlit_code = r'''\n",
        "import json, time\n",
        "from pathlib import Path\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "# --- Import your team pipeline here ---\n",
        "# from rag.pipeline import retrieve, generate_answer, run_query_and_log\n",
        "\n",
        "MISSING_EVIDENCE_MSG = \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "st.set_page_config(page_title=\"CS5542 Lab 4 ‚Äî Project RAG App\", layout=\"wide\")\n",
        "st.title(\"CS 5542 Lab 4 ‚Äî Project RAG Application\")\n",
        "st.caption(\"Project-aligned Streamlit UI + automatic logging + failure monitoring\")\n",
        "\n",
        "# Sidebar controls\n",
        "st.sidebar.header(\"Retrieval Settings\")\n",
        "retrieval_mode = st.sidebar.selectbox(\"retrieval_mode\", [\"tfidf\", \"dense\", \"sparse\", \"hybrid\", \"hybrid_rerank\"])\n",
        "top_k = st.sidebar.slider(\"top_k\", min_value=1, max_value=30, value=10, step=1)\n",
        "use_multimodal = st.sidebar.checkbox(\"use_multimodal\", value=True)\n",
        "\n",
        "st.sidebar.header(\"Logging\")\n",
        "log_path = st.sidebar.text_input(\"log file\", value=\"logs/query_metrics.csv\")\n",
        "\n",
        "# --- Mini gold set (replace with your team's Q1‚ÄìQ5) ---\n",
        "# Tip: keep the same structure as in your Lab 4 notebook so IDs match logs.\n",
        "MINI_GOLD = {\n",
        "    \"Q1\": {\"question\": \"Replace with your project Q1\", \"gold_evidence_ids\": []},\n",
        "    \"Q2\": {\"question\": \"Replace with your project Q2\", \"gold_evidence_ids\": []},\n",
        "    \"Q3\": {\"question\": \"Replace with your project Q3\", \"gold_evidence_ids\": []},\n",
        "    \"Q4\": {\"question\": \"Replace with your project Q4 (multimodal/table/figure)\", \"gold_evidence_ids\": []},\n",
        "    \"Q5\": {\"question\": \"Replace with your project Q5 (missing-evidence case)\", \"gold_evidence_ids\": []},\n",
        "}\n",
        "\n",
        "st.sidebar.header(\"Evaluation\")\n",
        "query_id = st.sidebar.selectbox(\"query_id (for logging)\", list(MINI_GOLD.keys()))\n",
        "use_gold_question = st.sidebar.checkbox(\"Use the gold-set question text\", value=True)\n",
        "\n",
        "# Main query\n",
        "default_q = MINI_GOLD[query_id][\"question\"] if use_gold_question else \"\"\n",
        "question = st.text_area(\"Enter your question\", value=default_q, height=120)\n",
        "run_btn = st.button(\"Run Query\")\n",
        "\n",
        "colA, colB = st.columns([2, 1])\n",
        "\n",
        "def ensure_logfile(path: str):\n",
        "    p = Path(path)\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not p.exists():\n",
        "        df = pd.DataFrame(columns=[\n",
        "            \"timestamp\",\"query_id\",\"retrieval_mode\",\"top_k\",\"latency_ms\",\n",
        "            \"Precision@5\",\"Recall@10\",\"evidence_ids_returned\",\"gold_evidence_ids\",\n",
        "            \"faithfulness_pass\",\"missing_evidence_behavior\"\n",
        "        ])\n",
        "        df.to_csv(p, index=False)\n",
        "\n",
        "def precision_at_k(retrieved_ids, gold_ids, k=5):\n",
        "    if not gold_ids:\n",
        "        return None\n",
        "    topk = retrieved_ids[:k]\n",
        "    hits = sum(1 for x in topk if x in set(gold_ids))\n",
        "    return hits / k\n",
        "\n",
        "def recall_at_k(retrieved_ids, gold_ids, k=10):\n",
        "    if not gold_ids:\n",
        "        return None\n",
        "    topk = retrieved_ids[:k]\n",
        "    hits = sum(1 for x in topk if x in set(gold_ids))\n",
        "    return hits / max(1, len(gold_ids))\n",
        "\n",
        "# ---- Placeholder demo logic (replace with imports from your /rag module) ----\n",
        "def retrieve_demo(q: str, top_k: int):\n",
        "    return [{\"chunk_id\":\"demo_doc\",\"citation_tag\":\"[demo_doc]\",\"score\":0.9,\"source\":\"data/docs/demo_doc.txt\",\"text\":\"demo evidence...\"}]\n",
        "\n",
        "def answer_demo(q: str, evidence: list):\n",
        "    if not evidence:\n",
        "        return MISSING_EVIDENCE_MSG\n",
        "    return f\"Grounded answer using {evidence[0]['citation_tag']} {evidence[0]['citation_tag']}\"\n",
        "\n",
        "def log_row(path: str, row: dict):\n",
        "    ensure_logfile(path)\n",
        "    df = pd.read_csv(path)\n",
        "    df = pd.concat([df, pd.DataFrame([row])], ignore_index=True)\n",
        "    df.to_csv(path, index=False)\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "if run_btn and question.strip():\n",
        "    t0 = time.time()\n",
        "    evidence = retrieve_demo(question, top_k=top_k)\n",
        "    answer = answer_demo(question, evidence)\n",
        "    latency_ms = round((time.time() - t0)*1000, 2)\n",
        "\n",
        "    retrieved_ids = [e[\"chunk_id\"] for e in evidence]\n",
        "    gold_ids = MINI_GOLD[query_id].get(\"gold_evidence_ids\", [])\n",
        "\n",
        "    p5 = precision_at_k(retrieved_ids, gold_ids, k=5)\n",
        "    r10 = recall_at_k(retrieved_ids, gold_ids, k=10)\n",
        "\n",
        "    with colA:\n",
        "        st.subheader(\"Answer\")\n",
        "        st.write(answer)\n",
        "\n",
        "        st.subheader(\"Evidence (Top-K)\")\n",
        "        st.json(evidence)\n",
        "\n",
        "    with colB:\n",
        "        st.subheader(\"Metrics\")\n",
        "        st.write({\"latency_ms\": latency_ms, \"Precision@5\": p5, \"Recall@10\": r10})\n",
        "\n",
        "    # Log the query using the selected Q1‚ÄìQ5 ID (not ad-hoc)\n",
        "    row = {\n",
        "        \"timestamp\": pd.Timestamp.utcnow().isoformat(),\n",
        "        \"query_id\": query_id,\n",
        "        \"retrieval_mode\": retrieval_mode,\n",
        "        \"top_k\": top_k,\n",
        "        \"latency_ms\": latency_ms,\n",
        "        \"Precision@5\": p5,\n",
        "        \"Recall@10\": r10,\n",
        "        \"evidence_ids_returned\": json.dumps(retrieved_ids),\n",
        "        \"gold_evidence_ids\": json.dumps(gold_ids),\n",
        "        \"faithfulness_pass\": \"Yes\" if answer != MISSING_EVIDENCE_MSG else \"Yes\",\n",
        "        \"missing_evidence_behavior\": \"Pass\"  # update with your rule if needed\n",
        "    }\n",
        "    log_row(log_path, row)\n",
        "    st.success(f\"Logged {query_id} to CSV.\")\n",
        "'''\n",
        "app_dir = Path(\"app\")\n",
        "app_dir.mkdir(parents=True, exist_ok=True)\n",
        "(app_dir / \"main.py\").write_text(streamlit_code, encoding=\"utf-8\")\n",
        "print(\"Wrote starter Streamlit app to:\", app_dir / \"main.py\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05c21ec8",
      "metadata": {
        "id": "05c21ec8"
      },
      "source": [
        "# 8) Optional Extension ‚Äî FastAPI Backend (Recommended for larger teams)\n",
        "\n",
        "If your team selects the **FastAPI extension**, create:\n",
        "- `api/server.py` with `POST /query`\n",
        "- Streamlit UI calls the API using `requests.post(...)`\n",
        "\n",
        "This separation mirrors real production systems:\n",
        "UI (Streamlit) ‚Üí API (FastAPI) ‚Üí Retrieval + LLM services\n",
        "\n",
        "Below is a minimal FastAPI starter you can generate.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "32168ff2",
      "metadata": {
        "id": "32168ff2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c12c4c3-7d09-45b0-fed5-ee77ebc54e56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote starter FastAPI server to: api/server.py\n",
            "\n",
            "Run locally (terminal):\n",
            "  uvicorn api.server:app --reload --port 8000\n"
          ]
        }
      ],
      "source": [
        "fastapi_code = r'''\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "app = FastAPI(title=\"CS5542 Lab 4 RAG Backend\")\n",
        "\n",
        "MISSING_EVIDENCE_MSG = \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "class QueryIn(BaseModel):\n",
        "    question: str\n",
        "    top_k: int = 10\n",
        "    retrieval_mode: str = \"hybrid\"\n",
        "    use_multimodal: bool = True\n",
        "\n",
        "@app.post(\"/query\")\n",
        "def query(q: QueryIn) -> Dict[str, Any]:\n",
        "    # TODO: import your real pipeline:\n",
        "    # evidence = retrieve(q.question, top_k=q.top_k, mode=q.retrieval_mode, use_multimodal=q.use_multimodal)\n",
        "    # answer = generate_answer(q.question, evidence)\n",
        "    evidence = [{\"chunk_id\":\"demo_doc\",\"citation_tag\":\"[demo_doc]\",\"score\":0.9,\"source\":\"data/docs/demo_doc.txt\",\"text\":\"demo evidence...\"}]\n",
        "    answer = f\"Grounded answer using {evidence[0]['citation_tag']} {evidence[0]['citation_tag']}\"\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"evidence\": evidence,\n",
        "        \"metrics\": {\"top_k\": q.top_k, \"retrieval_mode\": q.retrieval_mode},\n",
        "        \"failure_flag\": False\n",
        "    }\n",
        "'''\n",
        "api_dir = Path(\"api\")\n",
        "api_dir.mkdir(parents=True, exist_ok=True)\n",
        "(api_dir / \"server.py\").write_text(fastapi_code, encoding=\"utf-8\")\n",
        "print(\"Wrote starter FastAPI server to:\", api_dir / \"server.py\")\n",
        "\n",
        "print(\"\\nRun locally (terminal):\")\n",
        "print(\"  uvicorn api.server:app --reload --port 8000\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Temporary Build\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# We embed the pipeline logic (loading, indexing, retrieval) directly into the server file\n",
        "# so it runs independently of the notebook kernel.\n",
        "fastapi_code = r'''\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "app = FastAPI(title=\"CS5542 Lab 4 RAG Backend\")\n",
        "\n",
        "# --- 1. Global State & Data Loading ---\n",
        "# We store the index and evidence globally so they load once on startup\n",
        "global_state = {\n",
        "    \"vectorizer\": None,\n",
        "    \"tfidf_matrix\": None,\n",
        "    \"evidence\": []\n",
        "}\n",
        "\n",
        "def load_data_and_index():\n",
        "    \"\"\"Loads text files from ./data/docs and builds a TF-IDF index.\"\"\"\n",
        "    print(\"Loading data from ./data/docs...\")\n",
        "    docs_dir = \"./data/docs\"\n",
        "\n",
        "    # Simple loader matching your notebook's logic\n",
        "    items = []\n",
        "    if os.path.exists(docs_dir):\n",
        "        files = glob.glob(os.path.join(docs_dir, \"*.txt\")) + glob.glob(os.path.join(docs_dir, \"*.pdf\"))\n",
        "        for p in files:\n",
        "            # For simplicity in this demo server, we read text files directly.\n",
        "            # If using PDFs, you'd include PyMuPDF logic here or assume pre-converted .txts exist.\n",
        "            try:\n",
        "                # Fallback: try reading as text (works for the .txt demo files)\n",
        "                with open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "                    text = f.read()\n",
        "\n",
        "                items.append({\n",
        "                    \"evidence_id\": os.path.basename(p),\n",
        "                    \"source\": p,\n",
        "                    \"text\": text,\n",
        "                    \"citation_tag\": f\"[{os.path.basename(p)}]\"\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Skipping file {p}: {e}\")\n",
        "\n",
        "    if not items:\n",
        "        print(\"WARNING: No documents found in ./data/docs. Server will have empty index.\")\n",
        "        return\n",
        "\n",
        "    # Build TF-IDF Index\n",
        "    texts = [it[\"text\"] for it in items]\n",
        "    vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "    tfidf_matrix = vectorizer.fit_transform(texts)\n",
        "\n",
        "    global_state[\"evidence\"] = items\n",
        "    global_state[\"vectorizer\"] = vectorizer\n",
        "    global_state[\"tfidf_matrix\"] = tfidf_matrix\n",
        "    print(f\"Server ready: Indexed {len(items)} documents.\")\n",
        "\n",
        "# Load on startup\n",
        "@app.on_event(\"startup\")\n",
        "def startup_event():\n",
        "    load_data_and_index()\n",
        "\n",
        "# --- 2. Your Pipeline Functions (Ported from Notebook) ---\n",
        "\n",
        "def retrieve_tfidf(question: str, top_k: int = 5) -> List[Tuple[int, float]]:\n",
        "    vec = global_state[\"vectorizer\"]\n",
        "    mat = global_state[\"tfidf_matrix\"]\n",
        "\n",
        "    if vec is None or mat is None:\n",
        "        return []\n",
        "\n",
        "    q_vec = vec.transform([question])\n",
        "    sims = cosine_similarity(q_vec, mat).ravel()\n",
        "    # Get top_k indices\n",
        "    idxs = np.argsort(-sims)[:top_k]\n",
        "    return [(int(i), float(sims[i])) for i in idxs]\n",
        "\n",
        "def build_context(hit_ids: List[int], max_chars=2000) -> str:\n",
        "    parts = []\n",
        "    current_len = 0\n",
        "    for i in hit_ids:\n",
        "        item = global_state[\"evidence\"][i]\n",
        "        text = item[\"text\"]\n",
        "        tag = item[\"citation_tag\"]\n",
        "        # Simple truncation for context window\n",
        "        entry = f\"{tag} {text}\"\n",
        "        if current_len + len(entry) > max_chars:\n",
        "            break\n",
        "        parts.append(entry)\n",
        "        current_len += len(entry)\n",
        "    return \"\\n\\n\".join(parts)\n",
        "\n",
        "def extractive_answer(query: str, context: str) -> str:\n",
        "    \"\"\"Simple heuristic answer generator from your notebook.\"\"\"\n",
        "    if not context.strip():\n",
        "        return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "    # Heuristic: Find sentences with overlapping words\n",
        "    q_words = set(re.findall(r'[A-Za-z]+', query.lower()))\n",
        "    # Split by simple punctuation\n",
        "    sents = re.split(r'(?<=[.!?])\\s+', context)\n",
        "\n",
        "    scored = []\n",
        "    for s in sents:\n",
        "        w = set(re.findall(r'[A-Za-z]+', s.lower()))\n",
        "        score = len(q_words & w)\n",
        "        if score > 0:\n",
        "            scored.append((score, s.strip()))\n",
        "\n",
        "    scored.sort(key=lambda x: x[0], reverse=True)\n",
        "\n",
        "    # Return top 3 sentences or fallback\n",
        "    best = [s for sc, s in scored[:3]]\n",
        "    if best:\n",
        "        return \" \".join(best)\n",
        "    return \"Not enough evidence in the retrieved context.\"\n",
        "\n",
        "# --- 3. API Endpoint ---\n",
        "\n",
        "class QueryIn(BaseModel):\n",
        "    question: str\n",
        "    top_k: int = 5\n",
        "    retrieval_mode: str = \"hybrid\" # We use tfidf fallback in this server\n",
        "\n",
        "@app.post(\"/query\")\n",
        "def query(q: QueryIn) -> Dict[str, Any]:\n",
        "    # 1. Retrieve\n",
        "    # (Currently forcing TF-IDF pipeline for the server demo)\n",
        "    hits = retrieve_tfidf(q.question, top_k=q.top_k)\n",
        "\n",
        "    # 2. Format Evidence\n",
        "    evidence_list = []\n",
        "    hit_indices = []\n",
        "    for idx, score in hits:\n",
        "        item = global_state[\"evidence\"][idx]\n",
        "        evidence_list.append({\n",
        "            \"chunk_id\": item[\"evidence_id\"],\n",
        "            \"citation_tag\": item[\"citation_tag\"],\n",
        "            \"score\": score,\n",
        "            \"source\": item[\"source\"],\n",
        "            \"text\": item[\"text\"][:500] + \"...\" # Truncate for API response payload\n",
        "        })\n",
        "        hit_indices.append(idx)\n",
        "\n",
        "    # 3. Generate Answer\n",
        "    context = build_context(hit_indices)\n",
        "    answer = extractive_answer(q.question, context)\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer,\n",
        "        \"evidence\": evidence_list,\n",
        "        \"metrics\": {\n",
        "            \"top_k\": q.top_k,\n",
        "            \"retrieval_mode\": \"tfidf_server_baseline\"\n",
        "        },\n",
        "        \"failure_flag\": answer == \"Not enough evidence in the retrieved context.\"\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import uvicorn\n",
        "    # Allow running directly via python api/server.py\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "'''\n",
        "\n",
        "api_dir = Path(\"api\")\n",
        "api_dir.mkdir(parents=True, exist_ok=True)\n",
        "(api_dir / \"server.py\").write_text(fastapi_code, encoding=\"utf-8\")\n",
        "print(\"‚úÖ Wrote self-contained FastAPI server to:\", api_dir / \"server.py\")\n",
        "print(\"\\nRun locally (terminal):\")\n",
        "print(\"  uvicorn api.server:app --reload --port 8000\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqMRoTBcPGm6",
        "outputId": "381fdad7-f35a-43e9-ee4f-fe1097c6f9c8"
      },
      "id": "eqMRoTBcPGm6",
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Wrote self-contained FastAPI server to: api/server.py\n",
            "\n",
            "Run locally (terminal):\n",
            "  uvicorn api.server:app --reload --port 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9351032a",
      "metadata": {
        "id": "9351032a"
      },
      "source": [
        "# 9) Deployment checklist (Required)\n",
        "\n",
        "Choose **one** deployment route and publish the public link in your README:\n",
        "\n",
        "- HuggingFace Spaces (Streamlit)\n",
        "- Streamlit Cloud (GitHub-connected)\n",
        "- Render / Railway (GitHub-connected)\n",
        "\n",
        "## README must include\n",
        "1. Public deployment link  \n",
        "2. How to run locally:\n",
        "   - `pip install -r requirements.txt`\n",
        "   - `streamlit run app/main.py`\n",
        "3. A screenshot of:\n",
        "   - the UI\n",
        "   - evidence panel\n",
        "   - metrics panel\n",
        "4. Results snapshot:\n",
        "   - **5 queries √ó 2 retrieval modes**\n",
        "5. Failure analysis:\n",
        "   - 2 failure cases, root cause, proposed fix\n",
        "\n",
        "---\n",
        "\n",
        "# 10) Failure analysis template (Required)\n",
        "\n",
        "Document:\n",
        "1. **Retrieval failure** (wrong evidence or missed gold evidence)  \n",
        "2. **Grounding / missing-evidence failure** (safe behavior or citation enforcement)\n",
        "\n",
        "For each:\n",
        "- What happened?\n",
        "- Why did it happen (root cause)?\n",
        "- What change will you implement next?\n",
        "\n",
        "You can paste your analysis into your README under **Lab 4 Results**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67c11a7f",
      "metadata": {
        "id": "67c11a7f"
      },
      "source": [
        "# 11) Team checklist (quick)\n",
        "\n",
        "Before submission, verify:\n",
        "\n",
        "- [ ] Dataset, UI, and models are **project-aligned**\n",
        "- [ ] Streamlit app runs locally and shows: answer + evidence + metrics\n",
        "- [ ] `logs/query_metrics.csv` is auto-created and appended per query\n",
        "- [ ] Mini gold set Q1‚ÄìQ5 exists and P@5/R@10 computed when possible\n",
        "- [ ] Deployed link is public and listed in README\n",
        "- [ ] Two failure cases documented with fixes\n",
        "- [ ] `requirements.txt` and run instructions are correct\n",
        "- [ ] Individual survey submitted by each teammate\n",
        "\n",
        "---\n",
        "\n",
        "If you want to go beyond: add an evaluation dashboard, reranking integration, or FastAPI separation (extensions).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "4l9AWSmiSN26",
      "metadata": {
        "id": "4l9AWSmiSN26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b12bf831-9888-443e-8cf5-bdecd2ccd3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project retrieval hits: 5\n",
            "‚ö†Ô∏è Retrieval verification could not run.\n",
            "Reason: ValueError too many values to unpack (expected 2)\n"
          ]
        }
      ],
      "source": [
        "# Verification: retrieval should return non-empty results for a project-relevant query\n",
        "\n",
        "test_q = \"State Data Breach Notification Laws HIPAA GLBA\"\n",
        "\n",
        "try:\n",
        "    if 'retrieve_tfidf' in globals():\n",
        "        hits = retrieve_tfidf(test_q, top_k=5)\n",
        "    elif 'retrieve' in globals():\n",
        "        hits = retrieve(test_q, top_k=5)\n",
        "    else:\n",
        "        hits = []\n",
        "\n",
        "    if hits is None:\n",
        "        hits = []\n",
        "\n",
        "    n = len(hits) if hasattr(hits, '__len__') else 0\n",
        "    print('Project retrieval hits:', n)\n",
        "    assert n > 0, 'Retrieval returned empty results. Check corpus + indexing.'\n",
        "\n",
        "    # Show top hit preview so you know it matches your dataset\n",
        "    i0, s0 = hits[0]\n",
        "    print(\"Top hit:\", getattr(page_chunks[i0], \"chunk_id\", f\"chunk_{i0}\"), \"score=\", s0)\n",
        "    print(\"Preview:\", (page_chunks[i0].text or \"\")[:200].replace(\"\\n\", \" \"))\n",
        "\n",
        "except Exception as e:\n",
        "    print('‚ö†Ô∏è Retrieval verification could not run.')\n",
        "    print('Reason:', type(e).__name__, str(e)[:180])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71062ba0",
      "metadata": {
        "id": "71062ba0"
      },
      "source": [
        "\n",
        "## GitHub Deployment Example\n",
        "\n",
        "### Step 1 ‚Äî Push to GitHub\n",
        "```bash\n",
        "git init\n",
        "git add .\n",
        "git commit -m \"Lab4 deployment\"\n",
        "git branch -M main\n",
        "git remote add origin https://github.com/<username>/<repo>.git\n",
        "git push -u origin main\n",
        "```\n",
        "\n",
        "### Step 2 ‚Äî Deploy using Streamlit Cloud\n",
        "1. Visit https://share.streamlit.io\n",
        "2. Click **New App**\n",
        "3. Select your GitHub repository\n",
        "4. Branch: `main`\n",
        "5. App path: `app/main.py`\n",
        "6. Click **Deploy**\n",
        "\n",
        "### Step 3 ‚Äî Add deployment link\n",
        "Include the deployed application URL in your README.md file.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "275735636e1e404ca63dd80cb571ab34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22f48da85fd74cb7ac808a5f3f04c1f9",
              "IPY_MODEL_2a4d43663ee0465387a20b2fbcacf7a3",
              "IPY_MODEL_51e734f2fa4b463b87c4e29aeb341b79"
            ],
            "layout": "IPY_MODEL_0df2f653542c43309ad2ef1cd3ca8858"
          }
        },
        "22f48da85fd74cb7ac808a5f3f04c1f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e4cb615c9fc4c95a71c594322b9127c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_55eee262fe3d4bef853aaffd304d57b2",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "2a4d43663ee0465387a20b2fbcacf7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1fc65f206c84014b1db0543f01becd0",
            "max": 103,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1a0f227f2e9f4a149d48a39578341af4",
            "value": 103
          }
        },
        "51e734f2fa4b463b87c4e29aeb341b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a232016ed914045b38c2c2770f0f780",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e0c202b989c74cf69b581caa87abfd7b",
            "value": "‚Äá103/103‚Äá[00:00&lt;00:00,‚Äá168.52it/s,‚ÄáMaterializing‚Äáparam=pooler.dense.weight]"
          }
        },
        "0df2f653542c43309ad2ef1cd3ca8858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e4cb615c9fc4c95a71c594322b9127c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55eee262fe3d4bef853aaffd304d57b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1fc65f206c84014b1db0543f01becd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0f227f2e9f4a149d48a39578341af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a232016ed914045b38c2c2770f0f780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c202b989c74cf69b581caa87abfd7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dae3e14c8f144fe3a17a3a476ca21324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ab15182f96f4e9e90f3abad58446023",
              "IPY_MODEL_f48cd491e986400197afc8db59574cc6",
              "IPY_MODEL_56ab3f061dd24cd0a7048b613918c007"
            ],
            "layout": "IPY_MODEL_99d5a08f625a47a8a488e1d8823aa277"
          }
        },
        "5ab15182f96f4e9e90f3abad58446023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5172eefb0dd4939a0901db8093f33e8",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_65858356adc44fbaa9feba34102af832",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "f48cd491e986400197afc8db59574cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_858d2fbcc3fd4db5857ad0de2553bb44",
            "max": 105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f98110bbb17403d8929a1634a1c81c8",
            "value": 105
          }
        },
        "56ab3f061dd24cd0a7048b613918c007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40e87106195745da864b32752dde1cd3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0bed16b0a890433898a4a23cd79de160",
            "value": "‚Äá105/105‚Äá[00:00&lt;00:00,‚Äá424.54it/s,‚ÄáMaterializing‚Äáparam=classifier.weight]"
          }
        },
        "99d5a08f625a47a8a488e1d8823aa277": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5172eefb0dd4939a0901db8093f33e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65858356adc44fbaa9feba34102af832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "858d2fbcc3fd4db5857ad0de2553bb44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f98110bbb17403d8929a1634a1c81c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40e87106195745da864b32752dde1cd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bed16b0a890433898a4a23cd79de160": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f4d4229dc44457198c368d7578f22fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_427ceeb313e0446483ca1b79f879f6ea",
              "IPY_MODEL_9656b0b6f7e84d3098d8614d115f4f48",
              "IPY_MODEL_ac1abafcf62044ab90d2ce4a91495307"
            ],
            "layout": "IPY_MODEL_08c6349ac3c14f868351a58115da9bc0"
          }
        },
        "427ceeb313e0446483ca1b79f879f6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc8b237ab4cf4198b3f3c78e5c5ba057",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ac47f5caf8424454a8abb3b7dcd59d58",
            "value": "Loading‚Äáweights:‚Äá100%"
          }
        },
        "9656b0b6f7e84d3098d8614d115f4f48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_795933a588404cd7b0959509dbbe95a8",
            "max": 201,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1509904b35c244569846176b45737247",
            "value": 201
          }
        },
        "ac1abafcf62044ab90d2ce4a91495307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebbef4a5eac84b20832f36ae9362ce94",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8f7ad8effb4642d69b3f83efc3beb2b1",
            "value": "‚Äá201/201‚Äá[00:14&lt;00:00,‚Äá12.29it/s,‚ÄáMaterializing‚Äáparam=model.norm.weight]"
          }
        },
        "08c6349ac3c14f868351a58115da9bc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8b237ab4cf4198b3f3c78e5c5ba057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac47f5caf8424454a8abb3b7dcd59d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "795933a588404cd7b0959509dbbe95a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1509904b35c244569846176b45737247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ebbef4a5eac84b20832f36ae9362ce94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7ad8effb4642d69b3f83efc3beb2b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}